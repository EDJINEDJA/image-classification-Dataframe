{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importation des librairies nécéssaires","metadata":{}},{"cell_type":"code","source":"#Import libraries\nimport time\nimport seaborn as sns\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport numpy as np \nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,VotingClassifier\nfrom sklearn.ensemble import BaggingClassifier,GradientBoostingClassifier, ExtraTreesClassifier\nfrom sklearn.linear_model import SGDClassifier,LogisticRegression,LogisticRegressionCV\nfrom sklearn.linear_model import Perceptron, RidgeClassifier, PassiveAggressiveClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.naive_bayes import GaussianNB\n\n\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis,LinearDiscriminantAnalysis\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import validation_curve\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import f1_score\n\nfrom sklearn.multiclass import OneVsOneClassifier\nfrom sklearn.multiclass import OneVsRestClassifier\n\nfrom lightgbm import LGBMClassifier ","metadata":{"execution":{"iopub.status.busy":"2021-12-02T09:39:45.533519Z","iopub.execute_input":"2021-12-02T09:39:45.534139Z","iopub.status.idle":"2021-12-02T09:39:47.795138Z","shell.execute_reply.started":"2021-12-02T09:39:45.534044Z","shell.execute_reply":"2021-12-02T09:39:47.794302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#### Chargement des données\n\ntrain1 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train1slice.csv\")\ntrain2 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train2slices.csv\")\ntrain3 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train3slices.csv\")\ntrain4 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train4slices.csv\")\ntrain5 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train5slices.csv\")\ntrain6 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train6slices.csv\")\ntrain7 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train7slices.csv\")\ntrain8 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train8slices.csv\")\ntrain9 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train9slices.csv\")\ntrain10 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train10slices.csv\")\ntrain12 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train12slices.csv\")\ntrain15 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/train15slices.csv\")\n\ntest1 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test1slice.csv\")\ntest2 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test2slices.csv\")\ntest3 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test3slices.csv\")\ntest4 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test4slices.csv\")\ntest5 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test5slices.csv\")\ntest6 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test6slices.csv\")\ntest7 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test7slices.csv\")\ntest8 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test8slices.csv\")\ntest9 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test9slices.csv\")\ntest10 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test10slices.csv\") \ntest12 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test12slices.csv\")\ntest15 = pd.read_csv(\"/kaggle/input/smemi309-final-evaluation-challenge-2021/test15slices.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-12-02T09:39:50.70507Z","iopub.execute_input":"2021-12-02T09:39:50.705342Z","iopub.status.idle":"2021-12-02T09:39:53.250687Z","shell.execute_reply.started":"2021-12-02T09:39:50.705314Z","shell.execute_reply":"2021-12-02T09:39:53.249764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Définission de l'ensemble de test et de l'ensemble d'apprentissage\n\n# tain1slice\nX_train1 = train1.loc[:,train1.columns != 'label']\ny_train1 = train1.label\nX_test1 = test1.loc[:,test1.columns != 'label']\ny_test1 = test1.label\n\n# train2slices\nX_train2 = train2.loc[:,train2.columns != 'label']\ny_train2 = train2.label\nX_test2 = test2.loc[:,test2.columns != 'label']\ny_test2 = test2.label\n\n# train3slices\nX_train3 = train3.loc[:,train3.columns != 'label']\ny_train3 = train3.label\nX_test3 = test3.loc[:,test3.columns != 'label']\ny_test3 = test3.label\n\n# train4slices\nX_train4 = train4.loc[:,train4.columns != 'label']\ny_train4 = train4.label\nX_test4 = test4.loc[:,test4.columns != 'label']\ny_test4 = test4.label\n\n# train5slices\nX_train5 = train5.loc[:,train5.columns != 'label']\ny_train5 = train5.label \n\n# train6slices\nX_train6 = train6.loc[:,train6.columns != 'label']\ny_train6 = train6.label\nX_test6 = test6.loc[:,test6.columns != 'label']\ny_test6 = test6.label\n\n# train7slices\nX_train7 = train7.loc[:,train7.columns != 'label']\ny_train7 = train7.label\nX_test7 = test7.loc[:,test7.columns != 'label']\ny_test7 = test7.label\n\n# train8slices\nX_train8 = train8.loc[:,train8.columns != 'label']\ny_train8 = train8.label\nX_test8 = test8.loc[:,test8.columns != 'label']\ny_test8 = test8.label\n\n# train9slices\nX_train9 = train9.loc[:,train9.columns != 'label']\ny_train9 = train9.label\nX_test9 = test9.loc[:,test9.columns != 'label']\ny_test9 = test9.label\n\n# train10slices\nX_train10 = train10.loc[:,train10.columns != 'label']\ny_train10 = train10.label                      \nX_test10 = test10.loc[:,test10.columns != 'label']\ny_test10 = test10.label\n\n\n# train12slices\nX_train12 = train12.loc[:,train12.columns != 'label']\ny_train12 = train12.label                      \n\n\n# train15slices\nX_train15 = train15.loc[:,train15.columns != 'label']\ny_train15 = train15.label                      \n","metadata":{"execution":{"iopub.status.busy":"2021-12-02T09:39:55.984529Z","iopub.execute_input":"2021-12-02T09:39:55.98508Z","iopub.status.idle":"2021-12-02T09:39:56.060135Z","shell.execute_reply.started":"2021-12-02T09:39:55.985036Z","shell.execute_reply":"2021-12-02T09:39:56.059431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Etude des données de nos datasets\n\nDans cette partie, nous allons voir s'il existe une corrélation entre toutes les données de nos datasets.  \nCette étude aura pour but de voir l'influence des différents slices sur notre apprentissage.  \nAutrement dit, nous allons comparer le train5slices aux autres trains et voir à quel point ces derniers ont une influence sur notre apprrentissage. ","metadata":{}},{"cell_type":"markdown","source":"##  Matrices de corrélations","metadata":{}},{"cell_type":"code","source":"# Matrices de corrélation\ntrains = [train1, train2, train3, train4, train5,train6,train7,train8,train9,train10]\n\nfor i in range(len(trains)):\n    plt.matshow(trains[i].corr())\n    plt.colorbar()\n    plt.title('Matrice de Correlation_train{}'.format(i+1))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fonction pour le calcul de la corrélation entre les variables\n\ntrains = [train1, train2, train3, train4, train5,train6,train7,train8,train9,train10]\nmean_corr=[]\ndef Mean_correlation (trains):\n    for train  in trains:\n        mean = train.corr().mean().mean()\n        mean_corr.append(mean)\n    for i in np.arange(len(trains)):\n        print(\"mean correlation entre colonnes du train{} est : {} \\n\".format(i+1,mean_corr[i]))\n      ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" Mean_correlation (trains)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On remarque que les colonnes sont différentes. On peut donc utiliser toutes les données pour la prédiction des labels du train5slices","metadata":{}},{"cell_type":"markdown","source":"## Covariance entre les dataframes","metadata":{"execution":{"iopub.status.busy":"2021-11-27T15:25:58.691307Z","iopub.execute_input":"2021-11-27T15:25:58.691837Z","iopub.status.idle":"2021-11-27T15:25:58.736324Z","shell.execute_reply.started":"2021-11-27T15:25:58.691776Z","shell.execute_reply":"2021-11-27T15:25:58.734904Z"}}},{"cell_type":"code","source":"# Fonction pour le calcul de la covariance entre les dataframes\n\ntrains = [train1, train2, train3, train4, train5,train6,train7,train8,train9,train10]\nmean_corr=[]\ndef Mean_correlation (trains):\n    for train  in trains:\n        mean = train.corr().mean().mean()\n        mean_corr.append(mean)\n    for i in np.arange(len(trains)):\n        print(\"mean correlation entre colonnes du train{} est : {} \\n\".format(i+1,mean_corr[i]))\n      ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image representation for slice 1\nimages=[]\nimages=[np.asarray([X_train1.loc[k,:][i] for i in range(0,64)], dtype=np.float32).reshape(8,8) for k in range(0,len(X_train1))]\ni=0\nfor i in range(0,len(X_train1)):\n    plt.figure()\n    plt.title('training slice 1 label= {}'.format(y_train1[i]))\n    plt.imshow(images[i])\n    plt.colorbar()\n    plt.grid(False)\n    plt.show()\n    i=i+1\n\n    if i==5:\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Première partie: Apprentissage du train5slices et prédiction des labels du test5slices   ","metadata":{}},{"cell_type":"markdown","source":"### Models sklearn","metadata":{}},{"cell_type":"markdown","source":"1er cas :\nDans cette partie on divisera notre train5 en X_train,X_test,y_train,y_test de telle sorte que l'ensemble de test represente 25% de notre Dataset \n","metadata":{}},{"cell_type":"markdown","source":"2eme cas :on travaillera avec le train5 tout entier et le leaderboard nous servira à tester l'accuracy de notre best model","metadata":{}},{"cell_type":"markdown","source":"### Models pytorch\nDans cette partie on construira notre propre reseau de neurones afinde  voir si on peut faire augmenter notre accuracy","metadata":{}},{"cell_type":"markdown","source":"## Visualisation des données du train5slices","metadata":{}},{"cell_type":"code","source":"train5.describe().style.format('{:.2}').background_gradient(cmap=plt.get_cmap('coolwarm'),axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image representation for train5slices\nimages=[]\nimages=[np.asarray([X_train5.loc[k,:][i] for i in range(0,64)], dtype=np.float32).reshape(8,8) for k in range(0,len(X_train1))]\ni=0\nfor i in range(0,len(X_train5)):\n    plt.figure()\n    plt.title('training slice 5 label= {}'.format(y_train5[i]))\n    plt.imshow(images[i])\n    plt.colorbar()\n    plt.grid(False)\n    plt.show()\n    i=i+1\n\n    if i==5:\n        break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compte tenu du fait que nous n'avons les labels du test5slices, nous allons d'abord créer des données train et test pour le train5slices en vue d'un meilleur apprentissage.","metadata":{}},{"cell_type":"markdown","source":"#### 1er cas :","metadata":{}},{"cell_type":"code","source":"# Création des données train et test pour le train5slices\n\nX_train,X_test,y_train,y_test= train_test_split(X_train5, y_train5, test_size=0.25,random_state=0,shuffle=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:38:38.696187Z","iopub.execute_input":"2021-12-01T12:38:38.696679Z","iopub.status.idle":"2021-12-01T12:38:38.715048Z","shell.execute_reply.started":"2021-12-01T12:38:38.696637Z","shell.execute_reply":"2021-12-01T12:38:38.714212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nous allons comparer les modèles entre eux en vue de sélectionner ceux qui auront le meilleur score\n\nmodels = [AdaBoostClassifier(),RandomForestClassifier(), BaggingClassifier(), GradientBoostingClassifier(),\n          ExtraTreesClassifier(),\n         LogisticRegression(max_iter=10000),Perceptron(),RidgeClassifier(),PassiveAggressiveClassifier(),\n         SVC(),LinearSVC(),NuSVC(),\n         KNeighborsClassifier(), MLPClassifier(),DecisionTreeClassifier(),LGBMClassifier()]\nnames = [\"AdaBoost\",\"RandomForest\", \"BaggingClassifier\",\"GradientBoostingClassifier\",\"ExtraTrees\",\n         \"LogisticRegression\", \"Perceptron\", \"RidgeClassifier\",\"PassiveAggressiveClassifier\",\n         \"SVC\",\"LinearSVC()\", \"NuSVC\",\n         \"KNeighborsClassifier\", \"MLPClassifier\",\"DecisionTreeClassifier\",\"LGBMClassifier\"]\naccuracy=[]\nrecall=[]\ni=0\nfor model in models:\n    model.fit(X_train,y_train)\n    predicted = model.predict(X_test)\n    acc = accuracy_score(y_test, predicted)\n    rec= recall_score(y_test, predicted, average= 'weighted')\n    accuracy.append(acc)\n    recall.append(rec)\n#     print(\"Accuracy de \", names[i],\":\", accuracy[i])\n    i+=1\n\ndf1 = pd.DataFrame({'models' : names, 'accuracy_score' : accuracy, 'recall_score' : recall})\ndf1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sélection des meilleurs modèles en fonction de l'accuracy_score \n\nbest_models1 = df1[ (df1['accuracy_score'] >= 0.72) ]\nbest_models1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les classifieurs ayant obtenu un accuracy_score >= 70% sont :  \n-RandomForest  \n-ExtraTrees  \n-SCV  \n-NuSVC  \n-KNeighborsClassifier     \n\n\nNous allons maintenant les optimiser à l'aide d'un GridSearch","metadata":{}},{"cell_type":"markdown","source":"### 1- RandomForest","metadata":{}},{"cell_type":"code","source":" param_grid = {'n_estimators': np.arange(50,300,50),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(5,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid1 = GridSearchCV(RandomForestClassifier(), param_grid,n_jobs = -1,cv=5,verbose=1)\n\n# Fitting the estimator with training data\ngrid1.fit(X_train,y_train)\n\nprint(f\"Best Estmator: {grid1.best_estimator_}\", end=\"\\n\\n\")\nprint(f\"Best Score: {grid1.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF5 = pd.DataFrame(grid1.cv_results_)\nres_RF5    # Résultats du gridsearch pour le classifieur Random Forest du train5slice ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Estmator: RandomForestClassifier(criterion='entropy', max_depth=12, n_estimators=250,\n#####                       random_state=42)\n\n##### Best Score: 0.6759712326925661","metadata":{}},{"cell_type":"code","source":"model1 = RandomForestClassifier(criterion='entropy', max_depth=12, n_estimators=250,random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy de notre ensemble de test X_test","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel1.fit(X_train,y_train)\n\npredicted_test = model1.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_v = accuracy_score(y_test,predicted_test)\nprint(acc_v)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.7268518518518519  ","metadata":{}},{"cell_type":"markdown","source":"### 3- ExtraTrees","metadata":{}},{"cell_type":"code","source":" param_grid = {'n_estimators': np.arange(50,300,30),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(3,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid2 = GridSearchCV(ExtraTreesClassifier(), param_grid,n_jobs = -1,cv=5,verbose=1)\n\n# Fitting the estimator with training data\ngrid2.fit(X_train,y_train)\n\nprint(f\"Best Score: {grid2.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid2.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_ET5 = pd.DataFrame(grid2.cv_results_)\nres_ET5    # Résultats du gridsearch pour le classifieur ExtraTrees du train5slice ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.7224626965990052\n\n##### Best Estimator: ExtraTreesClassifier(max_depth=20, n_estimators=260, random_state=10)\n","metadata":{}},{"cell_type":"code","source":"model2 = ExtraTreesClassifier(max_depth=20, n_estimators=260, random_state=10)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:41:18.112485Z","iopub.execute_input":"2021-12-01T12:41:18.112813Z","iopub.status.idle":"2021-12-01T12:41:18.118475Z","shell.execute_reply.started":"2021-12-01T12:41:18.112783Z","shell.execute_reply":"2021-12-01T12:41:18.117791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\nmodel2.fit(X_train,y_train)\n\npredicted_test = model2.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_v = accuracy_score(y_test,predicted_test)\nprint(acc_v)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:41:20.674217Z","iopub.execute_input":"2021-12-01T12:41:20.674718Z","iopub.status.idle":"2021-12-01T12:41:22.350504Z","shell.execute_reply.started":"2021-12-01T12:41:20.674679Z","shell.execute_reply":"2021-12-01T12:41:22.349613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.72","metadata":{}},{"cell_type":"markdown","source":"### 3- SVC","metadata":{}},{"cell_type":"code","source":"param_grid = {'C': [0.1, 1, 10, 100],\n              'gamma': [1, 0.1, 0.01],\n              'kernel': ['linear','poly','rbf'],\n              'random_state' : [0,10,42]}\n\ngrid3 = GridSearchCV(SVC(), param_grid, refit = True, cv = 5, n_jobs = -1, verbose = 1)\n\n# Fitting the estimator with training data\ngrid3.fit(X_train,y_train)\n\nprint(f\"Best Score: {grid3.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Model: {grid3.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_SVC5 = pd.DataFrame(grid3.cv_results_)\nres_SVC5    # Résultats du gridsearch pour le classifieur SVC du train5slices\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.7282632074203522\n\n##### Best Model: SVC(C=10, gamma=0.1, random_state=0)","metadata":{}},{"cell_type":"code","source":"model3 = SVC(C=10, gamma=0.1, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:40:12.970774Z","iopub.execute_input":"2021-12-01T12:40:12.971057Z","iopub.status.idle":"2021-12-01T12:40:12.975594Z","shell.execute_reply.started":"2021-12-01T12:40:12.971027Z","shell.execute_reply":"2021-12-01T12:40:12.974692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\nmodel3.fit(X_train,y_train)\n\npredicted_test = model3.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_v = accuracy_score(y_test,predicted_test)\nprint(acc_v)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:40:15.748399Z","iopub.execute_input":"2021-12-01T12:40:15.748709Z","iopub.status.idle":"2021-12-01T12:40:16.765437Z","shell.execute_reply.started":"2021-12-01T12:40:15.748675Z","shell.execute_reply":"2021-12-01T12:40:16.764215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4- NuSVC","metadata":{}},{"cell_type":"code","source":"param_grid = {'nu' : [0.15,0.5],\n              'gamma': [1, 0.1, 0.01],\n              'random_state' : [0,10,42]}\n\ngrid4 = GridSearchCV(NuSVC(max_iter = 100), param_grid, refit = True, cv = 5, n_jobs = -1, verbose = 1)\n\n# Fitting the estimator with training data\ngrid4.fit(X_train,y_train)\n\nprint(f\"Best Score: {grid4.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Model: {grid4.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_NuSVC5 = pd.DataFrame(grid4.cv_results_)\nres_NuSVC5    # Résultats du gridsearch pour le classifieur SVC du train5slices\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.7108415109557736\n\n##### Best Model: NuSVC(gamma=1, nu=0.15, random_state=0)\n","metadata":{}},{"cell_type":"code","source":"model4 = NuSVC(gamma=1, nu=0.15, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:40:01.030951Z","iopub.execute_input":"2021-12-01T12:40:01.031274Z","iopub.status.idle":"2021-12-01T12:40:01.037337Z","shell.execute_reply.started":"2021-12-01T12:40:01.031243Z","shell.execute_reply":"2021-12-01T12:40:01.035853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\nmodel4.fit(X_train,y_train)\n\npredicted_test = model4.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_v = accuracy_score(y_test,predicted_test)\nprint(acc_v)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:40:03.697334Z","iopub.execute_input":"2021-12-01T12:40:03.697646Z","iopub.status.idle":"2021-12-01T12:40:05.032265Z","shell.execute_reply.started":"2021-12-01T12:40:03.697614Z","shell.execute_reply":"2021-12-01T12:40:05.030717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5- KNNClassifer","metadata":{}},{"cell_type":"code","source":"k_range = list(range(1,31))\nweight_options = [\"uniform\", \"distance\"]\n\nparam_grid = dict(n_neighbors = k_range, weights = weight_options)\n\ngrid5 = GridSearchCV(KNeighborsClassifier(), param_grid, refit = True, cv = 5, n_jobs = -1, verbose = 1)\n\n# Fitting the estimator with training data\ngrid5.fit(X_train,y_train)\n\nprint(f\"Best Score: {grid5.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Model: {grid5.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_KNN5 = pd.DataFrame(grid5.cv_results_)\nres_KNN5    # Résultats du gridsearch pour le classifieur KNN du train5slices\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##### Best Score: 0.7165748084419948\n\n##### Best Model: KNeighborsClassifier(n_neighbors=4, weights='distance')\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model5 = KNeighborsClassifier(n_neighbors=4, weights='distance')","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:39:37.681886Z","iopub.execute_input":"2021-12-01T12:39:37.682508Z","iopub.status.idle":"2021-12-01T12:39:37.688773Z","shell.execute_reply.started":"2021-12-01T12:39:37.682405Z","shell.execute_reply":"2021-12-01T12:39:37.687368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\nmodel5.fit(X_train,y_train)\n\npredicted_test = model5.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_v = accuracy_score(y_test,predicted_test)\nprint(acc_v)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:39:39.850786Z","iopub.execute_input":"2021-12-01T12:39:39.851093Z","iopub.status.idle":"2021-12-01T12:39:40.699216Z","shell.execute_reply.started":"2021-12-01T12:39:39.85106Z","shell.execute_reply":"2021-12-01T12:39:40.698147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 6- MLPClassifier","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First, we are defining parameter range\n\nparam_grid = {'hidden_layer_sizes': range(10,90,10),\n              'solver': ['sgd','adam'],\n              'learning_rate_init': [0.001,0.01],\n              'momentum' : [0.5,0.9,1],\n             'random_state' : [0,10,42]}\n\ngrid6 = GridSearchCV(estimator= MLPClassifier(max_iter = 10000),param_grid = param_grid, cv = 5, n_jobs = -1,verbose = 1)\n\n# fitting the model for grid search. First\ngrid6.fit(X_train, y_train)\n\n\nprint(f\"Best Score: {grid6.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid6.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\n\nres_MLP5 = pd.DataFrame(grid6.cv_results_)\nres_MLP5    # Résultats du gridsearch pour le classifieur ExtraTrees du train3slices","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Score: 0.7340233902406237\n\nBest Estimator: MLPClassifier(hidden_layer_sizes=50, learning_rate_init=0.01, max_iter=10000,\n              random_state=42, solver='sgd')\n","metadata":{}},{"cell_type":"code","source":"model6 = MLPClassifier(hidden_layer_sizes=50, learning_rate_init=0.01, max_iter=10000, random_state=42, solver='sgd')","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:38:56.308146Z","iopub.execute_input":"2021-12-01T12:38:56.308752Z","iopub.status.idle":"2021-12-01T12:38:56.31409Z","shell.execute_reply.started":"2021-12-01T12:38:56.308706Z","shell.execute_reply":"2021-12-01T12:38:56.313279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\nmodel6.fit(X_train,y_train)\n\npredicted_test = model6.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_v = accuracy_score(y_test,predicted_test)\nprint(acc_v)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:38:58.993277Z","iopub.execute_input":"2021-12-01T12:38:58.994147Z","iopub.status.idle":"2021-12-01T12:39:08.036578Z","shell.execute_reply.started":"2021-12-01T12:38:58.994104Z","shell.execute_reply":"2021-12-01T12:39:08.034824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"De tous les modèles testés, celui qui nous donne l'accuracy_score le plus élevé sur notre ensemble de test X_test est CSV\n\nNous allons maintenant appliquer ce modèle au test5slices afin de prédire les labels.\n\n\n#### Prédiction des labels du test5slices","metadata":{}},{"cell_type":"code","source":"model = SVC(C=10, gamma=0.1, random_state=0)    # =model3","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train,y_train)\n\npredicted = model.predict(test5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'label':predicted})\noutput['id'] = range(0,len(output))\n\ncolumnsTitles=[\"id\",\"label\"]\noutput = output.reindex(columns=columnsTitles)\n\noutput","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('submissionSVCV1.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On obtient un score de 0.69191 sur le leaderbord, ce qui n'est pas très intéressant.\n","metadata":{}},{"cell_type":"markdown","source":"2eme cas ","metadata":{}},{"cell_type":"markdown","source":"Le meilleur model nous ayant permis d'otenir une accuracy de 76% sur le leaderboard est le MLP avec comme transformation PCA ","metadata":{}},{"cell_type":"code","source":"### 1- MLPClassifier ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import make_pipeline\n\n# Création du pipeline et détermination des meilleurs paramètres\n\npipe = make_pipeline(PCA(), MLPClassifier())\n\n# First, we are defining parameter range\n\nparam_grid = {'pca__n_components': [ 30, 45,50, 64,200,300,320],\n              'mlpclassifier__hidden_layer_sizes': range(200,300,10),\n              'mlpclassifier__max_iter' : [10000],\n              'mlpclassifier__activation': ['tanh','relu'],\n              'mlpclassifier__solver': ['sgd','adam'],\n              'mlpclassifier__batch_size' : [10,20],\n              'mlpclassifier__learning_rate' : ['constant','adaptive'],\n              'mlpclassifier__learning_rate_init': [0.001,0.01]}\n\ngridBest = GridSearchCV(estimator=pipe,param_grid = param_grid, cv = 5, n_jobs = -1,verbose = 1)\n\n# fitting the model for grid search\ngridBest.fit(X_train5, y_train5)\n\nprint(gridBest.best_score_,gridBest.best_params_,gridBest.best_estimator_)","metadata":{"execution":{"iopub.status.busy":"2021-12-02T09:40:52.140792Z","iopub.execute_input":"2021-12-02T09:40:52.141083Z","iopub.status.idle":"2021-12-02T09:41:03.74858Z","shell.execute_reply.started":"2021-12-02T09:40:52.141052Z","shell.execute_reply":"2021-12-02T09:41:03.747189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = gridBest.best_estimator_   ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train5, y_train5)\n\npredicted = model.predict(test5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'label':predicted})\noutput['id'] = range(0,len(output))\n\ncolumnsTitles=[\"id\",\"label\"]\noutput = output.reindex(columns=columnsTitles)\n\noutput","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('submission.csv', index = False)  ## Meilleur score sur le leaderBoard","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Meilleur accuracy leaderboard=76%","metadata":{}},{"cell_type":"markdown","source":"### Furthermore model pytorch ","metadata":{}},{"cell_type":"code","source":"data=train5\nmean = np.array(data.iloc[:,1:]).flatten().mean()\nstd = np.array(data.iloc[:,1:]).flatten().std()\nprint('mean = ', mean)\nprint('std = ', std)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:15:52.261582Z","iopub.execute_input":"2021-12-01T12:15:52.261952Z","iopub.status.idle":"2021-12-01T12:15:52.285295Z","shell.execute_reply.started":"2021-12-01T12:15:52.261915Z","shell.execute_reply":"2021-12-01T12:15:52.283479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import nn, optim\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch\n\nclass Dataset(data.Dataset):\n    def __init__(self):\n        train = train5\n        train_labels = y_train5.values\n        train = train.drop(\"label\",axis=1).values.reshape(1077,1,8*5,8)\n        self.datalist = train\n        self.labels = train_labels\n    def __getitem__(self, index):\n        return torch.Tensor(self.datalist[index].astype(float)), self.labels[index]\n    def __len__(self):\n        return self.datalist.shape[0]\n\ntrain_Set = Dataset()\ntrainloader = torch.utils.data.DataLoader( dataset = train_Set , batch_size= 10, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:19:31.824953Z","iopub.execute_input":"2021-12-01T12:19:31.825238Z","iopub.status.idle":"2021-12-01T12:19:31.839336Z","shell.execute_reply.started":"2021-12-01T12:19:31.825209Z","shell.execute_reply":"2021-12-01T12:19:31.838414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_split = 0.2\nN_val_samples = round(validation_split * len(train_Set))\n\n## Split into two Subset\ncd_train_set, cd_val_set = torch.utils.data.random_split(train_Set, [len(train_Set) - N_val_samples, N_val_samples])\ntrain_dl = torch.utils.data.DataLoader(cd_train_set, batch_size=10, shuffle=True, num_workers=2)\nval_dl = torch.utils.data.DataLoader(cd_val_set, batch_size=10, shuffle=True, num_workers=2)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:19:35.261297Z","iopub.execute_input":"2021-12-01T12:19:35.261709Z","iopub.status.idle":"2021-12-01T12:19:35.270762Z","shell.execute_reply.started":"2021-12-01T12:19:35.261667Z","shell.execute_reply":"2021-12-01T12:19:35.269609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(320, 200)\n        self.fc2 = nn.Linear(200, 200)\n        #self.batch= nn.BatchNorm1d(200)\n        self.fc3 = nn.Linear(200, 200)\n        self.fc4 = nn.Linear( 200, 11)\n        \n        self.dropout = nn.Dropout(p=0.2)\n        \n    def forward(self, x):\n        x = x.view(x.shape[0], -1)\n        \n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        #x = F.relu(self.batch(x))\n        x = self.dropout(F.relu(self.fc3(x)))\n        x = F.log_softmax(self.fc4(x), dim=1)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:19:37.706231Z","iopub.execute_input":"2021-12-01T12:19:37.706709Z","iopub.status.idle":"2021-12-01T12:19:37.715411Z","shell.execute_reply.started":"2021-12-01T12:19:37.706667Z","shell.execute_reply":"2021-12-01T12:19:37.714555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Classifier()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.005)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:19:41.197734Z","iopub.execute_input":"2021-12-01T12:19:41.198176Z","iopub.status.idle":"2021-12-01T12:19:41.207707Z","shell.execute_reply.started":"2021-12-01T12:19:41.198138Z","shell.execute_reply":"2021-12-01T12:19:41.206748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.autograd import Variable\nfrom tqdm.notebook import tqdm\nfrom ipykernel import kernelapp as app\n\ndef train_net(net, criterion, optimizer, train_dl, val_dl, N_EPOCHS):\n\n    epoch_loss, epoch_acc, epoch_val_loss, epoch_val_acc = [], [], [], []\n    for epoch in tqdm(range(N_EPOCHS)): \n        ### TRAINING LOOP\n        running_loss = 0\n        running_accuracy = 0\n        # Put the network in training mode\n        model.train()\n        \n        for i, (images, labels) in enumerate(tqdm(train_dl)):\n                images = Variable(images)\n                labels = Variable(labels)\n        \n                optimizer.zero_grad()\n                outputs = model(images)\n        \n                loss = criterion(outputs, labels)\n                loss.backward()\n                optimizer.step()\n        \n                with torch.no_grad(): # disables gradient calculations\n                \n                        running_loss += loss.item()\n                        running_accuracy += (outputs.max(1)[1] == labels).sum().item()\n                    \n        print(\"EPOCH:\", i,\"Training accuracy:\", running_accuracy/float(len(cd_train_set)),\n              \"Training loss:\", running_loss/float(len(cd_train_set)))\n\n        epoch_loss.append(running_loss/len(cd_train_set))\n        epoch_acc.append(running_accuracy/len(cd_train_set))\n    \n        ### VALIDATION LOOP\n        # Put the network in validation mode\n        model.eval()\n\n        running_val_loss = 0\n        running_val_accuracy = 0\n        for i, (images, labels) in enumerate(tqdm(val_dl)):\n            \n            images = Variable(images)\n            labels = Variable(labels)\n        \n            outputs = model(images)\n        \n            loss = criterion(outputs, labels)\n            running_val_loss += loss.item()\n            running_val_accuracy += (outputs.max(1)[1] == labels).sum().item()\n        print(\"EPOCH:\", i,\"Validation  accuracy:\", running_val_accuracy/float(len(cd_val_set)),\n              \"Validation  loss:\", running_val_loss/float(len(cd_val_set)))\n\n        epoch_val_loss.append(running_val_loss/len(cd_val_set))\n        epoch_val_acc .append(running_val_accuracy/len(cd_val_set))\n        \n    return epoch_loss,epoch_acc,epoch_val_loss,epoch_val_acc,model\n    \n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:19:43.963968Z","iopub.execute_input":"2021-12-01T12:19:43.965722Z","iopub.status.idle":"2021-12-01T12:19:43.979123Z","shell.execute_reply.started":"2021-12-01T12:19:43.96565Z","shell.execute_reply":"2021-12-01T12:19:43.978371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_loss,epoch_acc,epoch_val_loss,epoch_val_acc,model = train_net(model, criterion, optimizer, train_dl, val_dl, N_EPOCHS=12)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:19:47.593602Z","iopub.execute_input":"2021-12-01T12:19:47.594195Z","iopub.status.idle":"2021-12-01T12:19:58.033328Z","shell.execute_reply.started":"2021-12-01T12:19:47.594149Z","shell.execute_reply":"2021-12-01T12:19:58.032011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.arange(12)\nplt.figure()\nplt.plot(x, epoch_acc, x, epoch_val_acc)\n\nplt.figure()\nplt.plot(x, epoch_loss, x, epoch_val_loss)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:20:01.457074Z","iopub.execute_input":"2021-12-01T12:20:01.457396Z","iopub.status.idle":"2021-12-01T12:20:01.871184Z","shell.execute_reply.started":"2021-12-01T12:20:01.457362Z","shell.execute_reply":"2021-12-01T12:20:01.87013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\ntest = test5\ntest = test.values.reshape(264,1,8,8*5).astype(float)\ntest = Variable(torch.Tensor(test))\n\npred = model(test)\n\n_, predlabel = torch.max(pred.data, 1)\npredlabel = predlabel.tolist()\n\npredlabel = pd.DataFrame(predlabel)\npredlabel.index = np.arange(264) \nid = np.arange(264) \nid = pd.DataFrame(id)\nid.index = id.index \n\npredlabel = pd.concat([id,predlabel], axis=1)\npredlabel.columns = [\"id\",\"label\"]\n\npredlabel.to_csv('predict.csv', index= False)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:20:18.678134Z","iopub.execute_input":"2021-12-01T12:20:18.678407Z","iopub.status.idle":"2021-12-01T12:20:18.697052Z","shell.execute_reply.started":"2021-12-01T12:20:18.678378Z","shell.execute_reply":"2021-12-01T12:20:18.696095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predlabel","metadata":{"execution":{"iopub.status.busy":"2021-12-01T12:20:22.630174Z","iopub.execute_input":"2021-12-01T12:20:22.630652Z","iopub.status.idle":"2021-12-01T12:20:22.646811Z","shell.execute_reply.started":"2021-12-01T12:20:22.630614Z","shell.execute_reply":"2021-12-01T12:20:22.64546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Deuxième partie : Analyse statistique pour évaluer l'influence du nombre de slices sur la précision finale  \n\nLe but est, dans un premier temps de voir comment le nombre de slices influence l'accuracy du train5slices puis, dans un second temps d'avoir si possible des résultats plus fins. \nPour chacun des datasets ci-dessus, nous allons :  \n- Tester plusieurs modèles en gardant leur configuration par défaut  \n- Garder les modèles ayant donné l'accuracy_score le plus élevé  \n- Optimiser les modèles sélectionnés grâce à un Gridsearch  \n- Garder \"LE\" modèle ayant obtenu l'accuracy_score le plus élevé  \n- Appliquer ce modèle à d'autres datasets dont le  train5slices  afin d'évaluer l'influence du nombre de slices sur l'accuracy finale.  ","metadata":{}},{"cell_type":"markdown","source":"## Train1slice","metadata":{}},{"cell_type":"markdown","source":"### 1- Tester plusieurs modèles en gardant leur configuration par défaut ","metadata":{}},{"cell_type":"code","source":"# Nous allons comparer les modèles entre eux en vue de sélectionner ceux qui auront le meilleur score\n\nmodels = [AdaBoostClassifier(),RandomForestClassifier(), BaggingClassifier(), GradientBoostingClassifier(),\n          ExtraTreesClassifier(),\n         LogisticRegression(max_iter=10000),Perceptron(),RidgeClassifier(),PassiveAggressiveClassifier(),\n         SVC(),LinearSVC(),NuSVC(),\n         KNeighborsClassifier(), MLPClassifier(),DecisionTreeClassifier(),LGBMClassifier()]\nnames = [\"AdaBoost\",\"RandomForest\", \"BaggingClassifier\",\"GradientBoostingClassifier\",\"ExtraTrees\",\n         \"LogisticRegression\", \"Perceptron\", \"RidgeClassifier\",\"PassiveAggressiveClassifier\",\n         \"SVC\",\"LinearSVC()\", \"NuSVC\",\n         \"KNeighborsClassifier\", \"MLPClassifier\",\"DecisionTreeClassifier\",\"LGBMClassifier\"]\naccuracy=[]\nrecall=[]\ni=0\nfor model in models:\n    model.fit(X_train1,y_train1)\n    predicted = model.predict(X_test1)\n    acc = accuracy_score(y_test1, predicted)\n    rec= recall_score(y_test1, predicted, average= 'weighted')\n    accuracy.append(acc)\n    recall.append(rec)\n#     print(\"Accuracy de \", names[i],\":\", accuracy[i])\n    i+=1\n\ndf1 = pd.DataFrame({'models' : names, 'accuracy_score' : accuracy, 'recall_score' : recall})\ndf1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2- Garder les modèles ayant donné l'accuracy_score le plus élevé","metadata":{}},{"cell_type":"code","source":"# Sélection des meilleurs modèles en fonction de l'accuracy_score \n\nbest_models1 = df1[ (df1['accuracy_score'] >= 0.65) ]\nbest_models1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Les modèles sélectionés à cette étape sont:  \n-RandomForest  \n-ExtraTrees    \n-LGBMClassifier","metadata":{}},{"cell_type":"markdown","source":"### 3- Optimiser les modèles sélectionnés grâce à un Gridsearch","metadata":{}},{"cell_type":"markdown","source":"#### a) Random Forest","metadata":{}},{"cell_type":"code","source":" param_grid = {'n_estimators': np.arange(50,300,50),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(3,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid1 = GridSearchCV(RandomForestClassifier(), param_grid,n_jobs = -1,cv=5,verbose=3)\n\n# Fitting the estimator with training data\ngrid1.fit(X_train1,y_train1)\n\nprint(f\"Best Score: {grid1.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF1 = pd.DataFrame(grid1.cv_results_)\nres_RF1    # Résultats du gridsearch pour le classifieur Random Forest du train1slice ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Best Estmator: {grid1.best_estimator_}\", end=\"\\n\\n\")\nprint(f\"Best Score: {grid1.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF1 = pd.DataFrame(grid1.cv_results_)\nres_RF1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Estmator: RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=250,\n##### random_state=0)\n\n##### Best Score: 0.6221403962101636\n","metadata":{}},{"cell_type":"code","source":"model1 = RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=250)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# stockeer les résultats\nres_RF1.to_csv(\"res_RF1.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_RF1.loc[res_RF1['mean_test_score'] == max(res_RF1.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Graphes de l'évolution de l'accuracy_score ","metadata":{}},{"cell_type":"code","source":"\nnbr_combision_paramètre=res_RF1.index\naccuracy=res_RF1['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaisons de paramètres\n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\")\nplt.title(\"variation de l'accuracy en foncion des combinaisons des paramètres\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### b) ExtraTrees\n\n","metadata":{}},{"cell_type":"code","source":" param_grid = {'n_estimators': np.arange(50,300,30),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(3,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid2 = GridSearchCV(ExtraTreesClassifier(), param_grid,n_jobs = -1,cv=5,verbose=1)\n\n# Fitting the estimator with training data\ngrid2.fit(X_train1,y_train1)\n\nprint(f\"Best Score: {grid2.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_ET1 = pd.DataFrame(grid2.cv_results_)\nres_ET1","metadata":{"execution":{"iopub.status.busy":"2021-12-01T22:34:43.341416Z","iopub.execute_input":"2021-12-01T22:34:43.342039Z","iopub.status.idle":"2021-12-01T23:04:19.516644Z","shell.execute_reply.started":"2021-12-01T22:34:43.341985Z","shell.execute_reply":"2021-12-01T23:04:19.515492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Best Score: {grid2.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid2.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_ET1 = pd.DataFrame(grid2.cv_results_)\nres_ET1","metadata":{"execution":{"iopub.status.busy":"2021-12-01T23:05:38.022646Z","iopub.execute_input":"2021-12-01T23:05:38.023092Z","iopub.status.idle":"2021-12-01T23:05:38.069402Z","shell.execute_reply.started":"2021-12-01T23:05:38.023051Z","shell.execute_reply":"2021-12-01T23:05:38.06866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_ET1.loc[res_ET1['mean_test_score'] == max(res_ET1.loc[:,'mean_test_score']),:]","metadata":{"execution":{"iopub.status.busy":"2021-12-01T23:05:44.110496Z","iopub.execute_input":"2021-12-01T23:05:44.110803Z","iopub.status.idle":"2021-12-01T23:05:44.146054Z","shell.execute_reply.started":"2021-12-01T23:05:44.11077Z","shell.execute_reply":"2021-12-01T23:05:44.144675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Graphes de l'évolution de l'accuracy_score pour chaque fold ","metadata":{}},{"cell_type":"code","source":"\nnbr_combision_paramètre=res_ET1.index\naccuracy=res_ET1['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaisons des paramètres\n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\")\nplt.title(\"variation de l'accuracy en foncion des combinaisons des paramètres\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-01T23:05:53.50795Z","iopub.execute_input":"2021-12-01T23:05:53.508294Z","iopub.status.idle":"2021-12-01T23:05:53.850422Z","shell.execute_reply.started":"2021-12-01T23:05:53.508256Z","shell.execute_reply":"2021-12-01T23:05:53.849453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.626761412575366\n\n##### Best Estimator: ExtraTreesClassifier(max_depth=18, n_estimators=110, random_state=0)","metadata":{}},{"cell_type":"code","source":"model2 = ExtraTreesClassifier(max_depth=18, n_estimators=110, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#res_ET1.to_csv(\"res_ET1.csv\")  # stocker ler résultat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### c) LGBMClassifier ","metadata":{}},{"cell_type":"code","source":"estimator = LGBMClassifier()\nparam_grid = {'n_estimators': [50,100,150,200,500],\n              'learning_rate':[0.1,0.01,1],\n              'max_depth' : np.arange(5,31)}\n\ngrid4 = GridSearchCV(estimator = estimator, param_grid = parameters,n_jobs = -1,cv=5,verbose=3)\n\n# Fitting the estimator with training data\ngrid4.fit(X_train1,y_train1)\n\nprint(f\"Best Score: {grid4.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid4.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_LGBM1 = pd.DataFrame(grid4.cv_results_)\nres_LGBM1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Best Score: 0.6100086132644272\n\n##### Best Estimator: LGBMClassifier(max_depth=6, n_estimators=180)\n","metadata":{}},{"cell_type":"code","source":"model3 = LGBMClassifier(max_depth=6, n_estimators=180)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_LGBM1.to_csv(\"res_LGBM1.csv\")  # stocker le résultat","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#n_estimators = [50,100,150,200,500]\n#x = range(len(n_estimators)\n#DF = res_LGBM1.iloc[:,[8,9,10,11,12,13]]\n#DF\n#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_LGBM1.loc[res_LGBM1['mean_test_score'] == max(res_LGBM1.loc[:,'mean_test_score']),:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for i in range(6):\n   # plt.plot(x,DF.iloc[:,i])\n    #plt.title('Accuracy_score : split{}'.format(i))\n   # plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"\nnbr_combision_paramètre=res_LGBM1.index\naccuracy=res_LGBM1['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaisons des paramètres\n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\")\nplt.title(\"variation de l'accuracy en foncion des combinaisons des paramètres\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4- Sélection du meilleur modèle","metadata":{}},{"cell_type":"markdown","source":"A l'issue de cette analyse, le modèle ayant obtenu le meilleur score est Extra Trees ","metadata":{}},{"cell_type":"code","source":"model = ExtraTreesClassifier(max_depth=18, n_estimators=110, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Appliquons maintenant ce modèle à d'autres Datasets  \n\n### 5- Application du modèle sur d'autres Datasets  \nNous allons d'abord voir comment il prédit les labels du train1slice    \n\n#### a) Train1sslice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train1,y_train1)\n\npredicted_test = model.predict(X_test1)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test1, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test1,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.6590909090909091","metadata":{}},{"cell_type":"markdown","source":"#### b) train2slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train2,y_train2)\n\npredicted_test = model.predict(X_test2)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test2, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test2,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7234848484848485","metadata":{}},{"cell_type":"markdown","source":"\n\n\n#### c) train3slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train3,y_train3)\n\npredicted_test = model.predict(X_test3)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test3, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test3,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.7386363636363636 \n\n\n#### d) train4slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train4,y_train4)\n\npredicted_test = model.predict(X_test4)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test4, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test4,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.7310606060606061\n","metadata":{}},{"cell_type":"markdown","source":"#### e) train5slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train,y_train)\n\npredicted_test = model.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test,predicted_test)\nprint(acc_t)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.74814","metadata":{}},{"cell_type":"markdown","source":"\n#### f) train6slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train6,y_train6)\n\npredicted_test = model.predict(X_test6)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test6, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test6,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.7083333333333334  ","metadata":{}},{"cell_type":"markdown","source":"#### g) train7slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train7,y_train7)\n\npredicted_test = model.predict(X_test7)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test7, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test7,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7159090909090909","metadata":{}},{"cell_type":"markdown","source":"#### h) train8slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train8,y_train8)\n\npredicted_test = model.predict(X_test8)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test8, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test8,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7348484848484849","metadata":{}},{"cell_type":"markdown","source":"\n#### i) train9slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train9,y_train9)\n\npredicted_test = model.predict(X_test9)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test9, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test9,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7272727272727273","metadata":{}},{"cell_type":"markdown","source":"#### j) train10slices \n","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train10,y_train10)\n\npredicted_test = model.predict(X_test10)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test10, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test10,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7613636363636364\n\nA l'issue de tous ces résultats, et surtout de l'accuracy_score obtenu pour l'ensemble de validation du train5slices, on déduit que l'accuracy_score du test5slices devrait être supérieur à 70%.Par ailleurs, on remarque tous les accuracy scores n'atteignent pas 0.75 en moyenne. On peut donc dire qu'avec 1 slice, les résultats ne sont pas très bons.  \n\n\nNous allons maintenant passer au train2slices. Nous réprenons le même processus que pour le train1slice.\n\n\n## Train2slices\n\n### 1- Tester plusieurs modèles en gardant leur configuration par défaut  ","metadata":{}},{"cell_type":"code","source":"# Nous allons comparer les modèles entre eux en vue de sélectionner ceux qui auront le meilleur score\n\nmodels = [AdaBoostClassifier(),RandomForestClassifier(), BaggingClassifier(), GradientBoostingClassifier(),\n          ExtraTreesClassifier(),\n         LogisticRegression(max_iter=10000),Perceptron(),RidgeClassifier(),PassiveAggressiveClassifier(),\n         SVC(),LinearSVC(),NuSVC(),\n         KNeighborsClassifier(), MLPClassifier(),DecisionTreeClassifier(),LGBMClassifier()]\nnames = [\"AdaBoost\",\"RandomForest\", \"BaggingClassifier\",\"GradientBoostingClassifier\",\"ExtraTrees\",\n         \"LogisticRegression\", \"Perceptron\", \"RidgeClassifier\",\"PassiveAggressiveClassifier\",\n         \"SVC\",\"LinearSVC()\", \"NuSVC\",\n         \"KNeighborsClassifier\", \"MLPClassifier\",\"DecisionTreeClassifier\",\"LGBMClassifier\"]\naccuracy=[]\nrecall=[]\ni=0\nfor model in models:\n    model.fit(X_train2,y_train2)\n    predicted = model.predict(X_test2)\n    acc = accuracy_score(y_test2, predicted)\n    rec= recall_score(y_test2, predicted, average= 'weighted')\n    accuracy.append(acc)\n    recall.append(rec)\n#     print(\"Accuracy de \", names[i],\":\", accuracy[i])\n    i+=1\n\ndf2 = pd.DataFrame({'models' : names, 'accuracy_score' : accuracy, 'recall_score' : recall})\ndf2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2- Garder les modèles ayant l'accuracy_score le plus élevé","metadata":{}},{"cell_type":"code","source":"# Sélection des meilleurs modèles en fonction de l'accuracy_score \n\nbest_models2 = df2[ (df2['accuracy_score'] >= 0.68) ]\nbest_models2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Les modèles sélectionnés à cette étape sont:  \n\n-RandomForest  \n-ExtraTrees  \n-SVC  \n-LGBMClassifier ","metadata":{}},{"cell_type":"markdown","source":"### 3- Optimiser les modèles sélectionnées grâce à un Gridsearch","metadata":{}},{"cell_type":"markdown","source":"#### a) RandomForest","metadata":{}},{"cell_type":"code","source":"\n param_grid = {'n_estimators': np.arange(50,300,50),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(3,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid1 = GridSearchCV(RandomForestClassifier(), param_grid,n_jobs = -1,cv=3,verbose=3)\n\n# Fitting the estimator with training data\ngrid1.fit(X_train2,y_train2)\n\n\nprint(f\"Best Estmator: {grid1.best_estimator_}\", end=\"\\n\\n\")\nprint(f\"Best Score: {grid1.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF2 = pd.DataFrame(grid1.cv_results_)\nres_RF2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Estimator: RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=200,\n#####                       random_state=0)\n\n##### Best Score: 0.6128133704735376","metadata":{}},{"cell_type":"code","source":"model1 = RandomForestClassifier(criterion='entropy', max_depth=14, n_estimators=200,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_RF2.to_csv(\"res_RF2.csv\")   ## stocker les résultats","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_RF2.loc[res_RF2['mean_test_score'] == max(res_RF2.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"\nnbr_combision_paramètre=res_RF2.index\naccuracy=res_RF2['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison des paramètre\n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### b) ExtraTrees","metadata":{}},{"cell_type":"code","source":" param_grid = {'n_estimators': np.arange(50,300,30),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(3,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid2 = GridSearchCV(ExtraTreesClassifier(), param_grid,n_jobs = -1,cv=3,verbose=3)\n\n# Fitting the estimator with training data\ngrid2.fit(X_train2,y_train2)\n\nprint(f\"Best Score: {grid2.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_ET2 = pd.DataFrame(grid2.cv_results_)\nres_ET2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Best Score: {grid2.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Model: {grid2.best_estimator_}\", end=\"\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.6341689879294337\n\n##### Best model: ExtraTreesClassifier(max_depth=17, n_estimators=170, random_state=0)","metadata":{}},{"cell_type":"code","source":"model2 = ExtraTreesClassifier(max_depth=17, n_estimators=170, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_ET2.to_csv(\"res_ET2.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_ET2.loc[res_ET2['mean_test_score'] == max(res_ET2.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"\nnbr_combision_paramètre=res_ET2.index\naccuracy=res_ET2['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison des paramètre\n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### c) SVC","metadata":{}},{"cell_type":"code","source":"param_grid = {'C': [0.1, 1, 10, 100],\n              'gamma': [1, 0.1, 0.01],\n              'kernel': ['linear','poly','rbf'],\n              'random_state' : [0,10,42]}\n\ngrid3 = GridSearchCV(SVC(), param_grid, refit = True, cv = 3, n_jobs = -1, verbose = 3)\n\n# Fitting the estimator with training data\ngrid3.fit(X_train2,y_train2)\n\nprint(f\"Best Score: {grid3.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Model: {grid3.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_SVC2 = pd.DataFrame(grid3.cv_results_)\nres_SVC2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.6434540389972145\n\n##### Best Model: SVC(C=10, gamma=1, random_state=0)","metadata":{}},{"cell_type":"code","source":"model3 = SVC(C=10, gamma=1, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_SVC2.to_csv(\"res_SCV2.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_SVC2.loc[res_SVC2['mean_test_score'] == max(res_SVC2.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"\nnbr_combision_paramètre=res_SVC2.index\naccuracy=res_SVC2['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison des paramètre\n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### d) LGBM","metadata":{}},{"cell_type":"code","source":"estimator = LGBMClassifier()\nparam_grid = {'n_estimators': [50,100,150,200,500],\n              'learning_rate':[0.1,0.01,1],\n              'max_depth' : np.arange(5,31)}\n\ngrid4 = GridSearchCV(estimator = estimator, param_grid = parameters,n_jobs = -1,cv=3,verbose=3)\n\n# Fitting the estimator with training data\ngrid4.fit(X_train2,y_train2)\n\nprint(f\"Best Score: {grid4.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid4.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_LGBM2 = pd.DataFrame(grid4.cv_results_)\nres_LGBM2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.6090993500464252\n\n##### Best Estimator: LGBMClassifier(max_depth=13, n_estimators=180)","metadata":{}},{"cell_type":"code","source":"model3 = LGBMClassifier(max_depth=13, n_estimators=180)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_LGBM2.to_csv(\"res_LGBM2.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_LGBM2.loc[res_LGBM2['mean_test_score'] == max(res_LGBM2.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"\nnbr_combision_paramètre=res_LGBM2.index\naccuracy=res_LGBM2['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison des paramètre\n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4- Sélection du meilleur modèle \n\nLe modèle ayant eu le meilleur score est SCV","metadata":{}},{"cell_type":"code","source":"model = SVC(C=10, gamma=1, random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:11:02.641625Z","iopub.execute_input":"2021-12-01T13:11:02.642753Z","iopub.status.idle":"2021-12-01T13:11:02.650981Z","shell.execute_reply.started":"2021-12-01T13:11:02.642695Z","shell.execute_reply":"2021-12-01T13:11:02.649866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Appliquons maintenant ce modèle à d'autres datasets \n\n### 5- Application du modèle sur d'autres Datasets\n\n\n#### a) Train1slice\n","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train1,y_train1)\n\npredicted_test = model.predict(X_test1)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test1, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test1,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.6477272727272727  ","metadata":{}},{"cell_type":"markdown","source":"\n#### b) train2slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train2,y_train2)\n\npredicted_test = model.predict(X_test2)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test2, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test2,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Acuracy_score = 0.7234848484848485","metadata":{}},{"cell_type":"markdown","source":"#### c) trains3lices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train3,y_train3)\n\npredicted_test = model.predict(X_test3)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test3, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test3,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Acuracy_score =0.7121212121212122","metadata":{}},{"cell_type":"markdown","source":"#### d) train4slices ","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train4,y_train4)\n\npredicted_test = model.predict(X_test4)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test4, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test4,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Acuracy_score =0.6893939393939394","metadata":{}},{"cell_type":"markdown","source":"\n#### e) train5slices \n\nNous utilisons les ensembles d'apprentissage et de test créés précédemment: X_train, y_train, X_test, y_test","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train,y_train)\n\npredicted_test = model.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.733333 ","metadata":{}},{"cell_type":"markdown","source":"#### f) train6slices ","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train6,y_train6)\n\npredicted_test = model.predict(X_test6)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test6, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test6,predicted_test)\nprint(acc_t)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:11:25.239699Z","iopub.execute_input":"2021-12-01T13:11:25.240612Z","iopub.status.idle":"2021-12-01T13:11:27.204273Z","shell.execute_reply.started":"2021-12-01T13:11:25.240548Z","shell.execute_reply":"2021-12-01T13:11:27.203306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.6590909090909091","metadata":{}},{"cell_type":"markdown","source":"#### g) Train7slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train7,y_train7)\n\npredicted_test = model.predict(X_test7)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test7, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test7,predicted_test)\nprint(acc_t)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:11:47.713197Z","iopub.execute_input":"2021-12-01T13:11:47.713739Z","iopub.status.idle":"2021-12-01T13:11:49.731717Z","shell.execute_reply.started":"2021-12-01T13:11:47.713697Z","shell.execute_reply":"2021-12-01T13:11:49.730631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.6590909090909091","metadata":{}},{"cell_type":"markdown","source":" \n\n\n#### h) Train8slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train8,y_train8)\n\npredicted_test = model.predict(X_test8)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test8, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test8,predicted_test)\nprint(acc_t)","metadata":{"execution":{"iopub.status.busy":"2021-12-01T13:12:02.582084Z","iopub.execute_input":"2021-12-01T13:12:02.58239Z","iopub.status.idle":"2021-12-01T13:12:04.817782Z","shell.execute_reply.started":"2021-12-01T13:12:02.582355Z","shell.execute_reply":"2021-12-01T13:12:04.816838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.6439393939393939\n","metadata":{}},{"cell_type":"markdown","source":"#### i) Train9slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train9,y_train9)\n\npredicted_test = model.predict(X_test9)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test9, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test9,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.6439393939393939","metadata":{}},{"cell_type":"markdown","source":"#### j) Train10slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train10,y_train10)\n\npredicted_test = model.predict(X_test10)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test10, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test10,predicted_test)\nprint(acc_t)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.6477272727272727  \n\nA l'issue de tous ces résultats, et surtout de l'accuracy_score obtenu pour l'ensemble de validation du train5slices, on déduit que l'accuracy_score du test5slices devrait tourner autour de 70%.Par ailleurs, on remarque tous les accuracy scores n'atteignent pas 0.75. On peut donc dire qu'avec 2 slices, les résultats ne sont pas très bons.  Les résultats obtenus ne sont pas très différents de ceux que l'on obtient avec 1 slice.  \n\n\nNous allons maintenant passer au train3slices. Nous réprenons le même processus que pour précédemment.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Train3slices","metadata":{}},{"cell_type":"markdown","source":"### 1- Tester plusieurs modèles ","metadata":{}},{"cell_type":"code","source":"# Nous allons comparer les modèles entre eux en vue de sélectionner ceux qui auront le meilleur score\n\nmodels = [AdaBoostClassifier(),RandomForestClassifier(), BaggingClassifier(), GradientBoostingClassifier(),\n          ExtraTreesClassifier(),\n         LogisticRegression(max_iter=10000),Perceptron(),RidgeClassifier(),PassiveAggressiveClassifier(),\n         SVC(),LinearSVC(),NuSVC(),\n         KNeighborsClassifier(), MLPClassifier(),DecisionTreeClassifier(),LGBMClassifier()]\nnames = [\"AdaBoost\",\"RandomForest\", \"BaggingClassifier\",\"GradientBoostingClassifier\",\"ExtraTrees\",\n         \"LogisticRegression\", \"Perceptron\", \"RidgeClassifier\",\"PassiveAggressiveClassifier\",\n         \"SVC\",\"LinearSVC()\", \"NuSVC\",\n         \"KNeighborsClassifier\", \"MLPClassifier\",\"DecisionTreeClassifier\",\"LGBMClassifier\"]\naccuracy=[]\nrecall=[]\ni=0\nfor model in models:\n    model.fit(X_train3,y_train3)\n    predicted = model.predict(X_test3)\n    acc = accuracy_score(y_test3, predicted)\n    rec= recall_score(y_test3, predicted, average= 'weighted')\n    accuracy.append(acc)\n    recall.append(rec)\n#     print(\"Accuracy de \", names[i],\":\", accuracy[i])\n    i+=1\n\ndf3 = pd.DataFrame({'models' : names, 'accuracy_score' : accuracy, 'recall_score' : recall})\ndf3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2- Modèles ayant obtenu le score le plus élevé\n\n\n\nNous remarquons qu'avec les mêmes classifierurs que qand les deux cas précédent, les valeurs de l'accuracy_score sont plus élévées. Nous allons donc garder les modèles ayant un score >= 72%","metadata":{}},{"cell_type":"code","source":"# Sélection des meilleurs modèles en fonction de l'accuracy_score \n\nbest_models3 = df3[ (df3['accuracy_score'] >= 0.72) ]\nbest_models3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les modèles retenus à cette étape sont :   \n-ExtraTrees  \n-MLPClassifier\n\n\n\n### 3- Optimiser les modèles retenus grâce à un GridSearch","metadata":{}},{"cell_type":"markdown","source":"#### a) ExtraTrees","metadata":{}},{"cell_type":"code","source":" param_grid = {'n_estimators': np.arange(50,300,30),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(3,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid1 = GridSearchCV(ExtraTreesClassifier(), param_grid,n_jobs = -1,cv=3,verbose=1)\n\n# Fitting the estimator with training data\ngrid1.fit(X_train3,y_train3)\n\nprint(f\"Best Score: {grid1.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_ET3 = pd.DataFrame(grid1.cv_results_)\nres_ET3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Best Estimator: {grid1.best_estimator_}\", end=\"\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.6555246053853295\n##### Best Etimator : ExtraTreesClassifier(max_depth=15, n_estimators=200, random_state=10)\n","metadata":{}},{"cell_type":"code","source":"res_ET3.to_csv(\"res_ET3.csv\",index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_ET3.loc[res_ET3['mean_test_score'] == max(res_ET3.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"\nnbr_combision_paramètre=res_ET3.index\naccuracy=res_ET3['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison des paramètre\n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### b) MLPClassifier","metadata":{}},{"cell_type":"code","source":"# First, we are defining parameter range\n\nparam_grid = {'hidden_layer_sizes': range(10,90,10),\n              'solver': ['sgd','adam'],\n              'learning_rate_init': [0.001,0.01],\n              'momentum' : [0.5,0.9,1]}\n\ngrid2 = GridSearchCV(estimator= MLPClassifier(),param_grid = param_grid, cv = 3, n_jobs = -1,verbose = 1)\n\n# fitting the model for grid search. First\ngrid2.fit(X_train3, y_train3)\n\n\nprint(f\"Best Score: {grid2.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid2.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\n\nres_MLP3 = pd.DataFrame(grid2.cv_results_)\nres_MLP3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.6583101207056639\n\n##### Best Estimator: MLPClassifier(hidden_layer_sizes=70, learning_rate_init=0.01, momentum=1)","metadata":{}},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_MLP3.loc[res_MLP3['mean_test_score'] == max(res_MLP3.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"\nnbr_combision_paramètre=res_MLP3.index\naccuracy=res_MLP3['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison des paramètre\n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4- Sélection du meilleur modèle\n\n\nLe modèle ayant obtenu le meilleur score est MLP","metadata":{}},{"cell_type":"code","source":"model = MLPClassifier(hidden_layer_sizes=70, learning_rate_init=0.01, momentum=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5) Application du modèle sur d'autres datasets","metadata":{}},{"cell_type":"markdown","source":"#### a) Train1slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train1,y_train1)\n\npredicted_test = model.predict(X_test1)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test1, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test1,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =  0.6515151515151515\n","metadata":{}},{"cell_type":"markdown","source":"#### b) train2slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train2,y_train2)\n\npredicted_test = model.predict(X_test2)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test2, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test1,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.6704545454545454","metadata":{}},{"cell_type":"markdown","source":"#### c) train3slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train3,y_train3)\n\npredicted_test = model.predict(X_test3)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test3, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \n\nacc_t = accuracy_score(y_test3,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =  0.7121212121212122","metadata":{}},{"cell_type":"markdown","source":"\n\n#### d) Train4slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train4,y_train4)\n\npredicted_test = model.predict(X_test4)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test4, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \n\nacc_t = accuracy_score(y_test4,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7007575757575758","metadata":{}},{"cell_type":"markdown","source":"\n#### e) Train5slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train,y_train)\n\npredicted_test = model.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.7333333333333333  \n\n\n#### f) Train6slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train6,y_train6)\n\npredicted_test = model.predict(X_test6)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test6, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test6,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.696969696969697","metadata":{}},{"cell_type":"markdown","source":"#### g) Train7slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train7,y_train7)\n\npredicted_test = model.predict(X_test7)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test7, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test7,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.696969696969697","metadata":{}},{"cell_type":"markdown","source":"\n#### h) Train8slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train8,y_train8)\n\npredicted_test = model.predict(X_test8)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test8, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test8,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.7272727272727273\n\n\n#### i) Train9slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train9,y_train9)\n\npredicted_test = model.predict(X_test9)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test9, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test9,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.6893939393939394\n\n\n#### j) Train10slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train10,y_train10)\n\npredicted_test = model.predict(X_test10)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test10, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test10,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.66666666666666  \n\nA l'issue de nos analyses, on remarque que les résulats obtenus en appliquant le modèle sur d'autres Datasets est légèrement plus élevé que dans les cas précédents. Cela veut dire qu'avec 3 slices, nos modèles apprennent déjà un peu mieux.Cepedant, l'accuracy du test3slices(=0.7121212121212122) est inférieur que celui du test2slices(=0.7234848484848485). Par conséquent,le fait d'avoir plus de slices n'augmente pas automatiquement l'accuracy. Finalement, On remarque que l'accuracy du test5slices n'a pas vraiment évolué par rapport au cas précédent.\n\nPassons maintenant au train4slices. On répète le même processus.  \n\n\n## Train4slices\n\n### 1- Tester plusieurs modèles","metadata":{}},{"cell_type":"code","source":"# Nous allons comparer les modèles entre eux en vue de sélectionner ceux qui auront le meilleur score\n\nmodels = [AdaBoostClassifier(),RandomForestClassifier(), BaggingClassifier(), GradientBoostingClassifier(),\n          ExtraTreesClassifier(),\n         LogisticRegression(max_iter=10000),Perceptron(),RidgeClassifier(),PassiveAggressiveClassifier(),\n         SVC(),LinearSVC(),NuSVC(),\n         KNeighborsClassifier(), MLPClassifier(),DecisionTreeClassifier(),LGBMClassifier()]\nnames = [\"AdaBoost\",\"RandomForest\", \"BaggingClassifier\",\"GradientBoostingClassifier\",\"ExtraTrees\",\n         \"LogisticRegression\", \"Perceptron\", \"RidgeClassifier\",\"PassiveAggressiveClassifier\",\n         \"SVC\",\"LinearSVC()\", \"NuSVC\",\n         \"KNeighborsClassifier\", \"MLPClassifier\",\"DecisionTreeClassifier\",\"LGBMClassifier\"]\naccuracy=[]\nrecall=[]\ni=0\nfor model in models:\n    model.fit(X_train4,y_train4)\n    predicted = model.predict(X_test4)\n    acc = accuracy_score(y_test4, predicted)\n    rec= recall_score(y_test4, predicted, average= 'weighted')\n    accuracy.append(acc)\n    recall.append(rec)\n#     print(\"Accuracy de \", names[i],\":\", accuracy[i])\n    i+=1\n\ndf4 = pd.DataFrame({'models' : names, 'accuracy_score' : accuracy, 'recall_score' : recall})\ndf4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2- Modèles ayant donné l'accuracy_score le plus élevé","metadata":{}},{"cell_type":"code","source":"# Sélection des meilleurs modèles en fonction de l'accuracy_score \n\nbest_models4 = df4[ (df4['accuracy_score'] >= 0.72) ]\nbest_models4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les modèles retenus à ce stade sont : ExtraTrees, MLPClassifier et LGBMClassifier","metadata":{}},{"cell_type":"markdown","source":"### 3- Optimisation des modèles grâce à un GridSearch","metadata":{}},{"cell_type":"markdown","source":"#### a) ExtraTrees","metadata":{}},{"cell_type":"code","source":" param_grid = {'n_estimators': np.arange(50,300,30),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(3,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid1 = GridSearchCV(ExtraTreesClassifier(), param_grid,n_jobs = -1,cv=3,verbose=1)\n\n# Fitting the estimator with training data\ngrid1.fit(X_train4,y_train4)\n\nprint(f\"Best Score: {grid1.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid1.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_ET4 = pd.DataFrame(grid1.cv_results_)\nres_ET4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Best Score: 0.6629526462395542\n\n#### Best Estimator: ExtraTreesClassifier(max_depth=14, n_estimators=200, random_state=10)","metadata":{}},{"cell_type":"code","source":"model1 = ExtraTreesClassifier(max_depth=14, n_estimators=200, random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_ET4.to_csv(\"res_ET4.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_ET4.loc[res_ET4['mean_test_score'] == max(res_ET4.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"nbr_combision_paramètre=res_ET4.index\naccuracy=res_ET4['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison \n\nplt.plot(nbr_combision_paramètre,accuracy)\nplt.title(\"variation de l'accuracy en foncion des combinaisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### b) MLPClassifier","metadata":{}},{"cell_type":"code","source":"estimator = MLPClassifier(max_iter=100)\n\nparameters = {\n    'hidden_layer_sizes': [(10,30,10),(20,)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive','invscaling'],\n    'batch_size' : [10,30,60]\n}\n\ngrid2 = GridSearchCV(estimator = estimator, param_grid = parameters,n_jobs = -1,cv=3,verbose=1)\n\n# Fitting the estimator with training data\ngrid2.fit(X_train4,y_train4)\n\nprint(f\"Best Score: {grid2.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid2.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_MLP4 = pd.DataFrame(grid1.cv_results_)\nres_MLP4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Best Score: 0.6332404828226554\n\n##### Best Estimator: MLPClassifier(batch_size=10, hidden_layer_sizes=(20,), learning_rate='adaptive',\n #####             max_iter=100)","metadata":{}},{"cell_type":"code","source":"model2 = MLPClassifier(batch_size=10, hidden_layer_sizes=(20,), learning_rate='adaptive',max_iter=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_MLP4.to_csv(\"res_MLP4.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_MLP4.loc[res_MLP4['mean_test_score'] == max(res_MLP4.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"nbr_combision_paramètre=res_MLP4.index\naccuracy=res_MLP4['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison \n\nplt.plot(nbr_combision_paramètre,accuracy)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### c) LGBMClassifier","metadata":{}},{"cell_type":"code","source":"estimator = LGBMClassifier()\nparam_grid = {'n_estimators': [50,100,150,200,500],\n              'learning_rate':[0.1,0.01,1],\n              'max_depth' : np.arange(5,31)}\n\ngrid3 = GridSearchCV(estimator = estimator, param_grid = param_grid,n_jobs = -1,cv=3,verbose=2)\n\n# Fitting the estimator with training data\ngrid3.fit(X_train4,y_train4)\n\nprint(f\"Best Score: {grid3.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid3.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_LGBM4 = pd.DataFrame(grid3.cv_results_)\nres_LGBM4    # Résultats du gridsearch pour le classifieur LGBM du train2slice ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Best Score: 0.6081708449396471","metadata":{}},{"cell_type":"code","source":"\n\nmodel3 = LGBMClassifier(max_depth=5, n_estimators=200)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_LGBM4.loc[res_LGBM4['mean_test_score'] == max(res_LGBM4.loc[:,'mean_test_score']),:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"nbr_combision_paramètre=res_LGBM4.index\naccuracy=res_LGBM4['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaisons \n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\")\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4- Sélection du meilleur modèle\nLe modèle ayant eu le meilleur score est ExtraTrees","metadata":{}},{"cell_type":"code","source":"model =ExtraTreesClassifier(max_depth=14, n_estimators=200, random_state=10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5) Application du modèle sur d'autres datasets","metadata":{}},{"cell_type":"markdown","source":"#### a) Train1slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train1,y_train1)\n\npredicted_test = model.predict(X_test1)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test1, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test1,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Accuracy_score =  0.6931818181818182","metadata":{}},{"cell_type":"markdown","source":"#### b) train2slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train2,y_train2)\n\npredicted_test = model.predict(X_test2)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test2, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test2,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Accuracy_score = 0.7007575757575758","metadata":{}},{"cell_type":"markdown","source":"\n\n#### c) train3slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train3,y_train3)\n\npredicted_test = model.predict(X_test3)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test3, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test3,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Accuracy_score =  0.7348484848484849\n\n#### d) train4slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train4,y_train4)\n\npredicted_test = model.predict(X_test4)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test4, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test4,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Accuracy_score = 0.7424242424242424\n\n#### e) train5slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train,y_train)\n\npredicted_test = model.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Accuracy_score = 0.7074074074074074 \n\n\n#### f) Train6slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train6,y_train6)\n\npredicted_test = model.predict(X_test6)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test6, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test6,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Accuracy_score = 0.7386363636363636 \n\n\n#### g) Train7slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train7,y_train7)\n\npredicted_test = model.predict(X_test7)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test7, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test7,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Accuracy_score =0.7272727272727273  \n\n\n#### h) Train8slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train8,y_train8)\n\npredicted_test = model.predict(X_test8)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test7, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test8,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Accuracy_score =0.7196969696969697\n\n\n#### i) Train9slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train9,y_train9)\n\npredicted_test = model.predict(X_test9)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test9, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test9,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Accuracy_score = 0.7537878787878788  \n\n\n#### j) Train10slices","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train10,y_train10)\n\npredicted_test = model.predict(X_test10)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test10, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy \nacc_t = accuracy_score(y_test10,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score = 0.75\n\n\nA l'issue de nos analyses, on remarque que les résulats obtenus en appliquant le modèle sur d'autres Datasets est légèrement plus élevé que dans les cas précédents. Cela veut dire qu'avec 4 slices, nos modèles apprennent un peu mieux.  \n\nPassons maintenant au train4slices. On répète le même processus.  \n\n\n## Train6slices\n\n### 1- Tester plusieurs modèles","metadata":{}},{"cell_type":"code","source":"# Nous allons comparer les modèles entre eux en vue de sélectionner ceux qui auront le meilleur score\n\nmodels = [AdaBoostClassifier(),RandomForestClassifier(), BaggingClassifier(), GradientBoostingClassifier(),\n          ExtraTreesClassifier(),\n         LogisticRegression(max_iter=10000),Perceptron(),RidgeClassifier(),PassiveAggressiveClassifier(),\n         SVC(),LinearSVC(),NuSVC(),\n         KNeighborsClassifier(), MLPClassifier(),DecisionTreeClassifier(),LGBMClassifier()]\nnames = [\"AdaBoost\",\"RandomForest\", \"BaggingClassifier\",\"GradientBoostingClassifier\",\"ExtraTrees\",\n         \"LogisticRegression\", \"Perceptron\", \"RidgeClassifier\",\"PassiveAggressiveClassifier\",\n         \"SVC\",\"LinearSVC()\", \"NuSVC\",\n         \"KNeighborsClassifier\", \"MLPClassifier\",\"DecisionTreeClassifier\",\"LGBMClassifier\"]\naccuracy=[]\nrecall=[]\ni=0\nfor model in models:\n    model.fit(X_train6,y_train6)\n    predicted = model.predict(X_test6)\n    acc = accuracy_score(y_test6, predicted)\n    rec= recall_score(y_test6, predicted, average= 'weighted')\n    accuracy.append(acc)\n    recall.append(rec)\n#     print(\"Accuracy de \", names[i],\":\", accuracy[i])\n    i+=1\n\ndf6 = pd.DataFrame({'models' : names, 'accuracy_score' : accuracy, 'recall_score' : recall})\ndf6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2- Modèles ayant donné l'accuracy_score le plus élevé","metadata":{}},{"cell_type":"code","source":"# Sélection des meilleurs modèles en fonction de l'accuracy_score \n\nbest_models6 = df6[ (df6['accuracy_score'] >= 0.68) ]\nbest_models6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les modèles retenus à ce stade sont : ExtraTrees, MLPClassifier,SVC","metadata":{}},{"cell_type":"markdown","source":"### 3- Optimisation des modèles grâce à un GridSearch","metadata":{}},{"cell_type":"markdown","source":"#### a) ExtraTrees","metadata":{}},{"cell_type":"code","source":" param_grid = {'n_estimators': np.arange(50,300,30),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(3,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid6 = GridSearchCV(ExtraTreesClassifier(), param_grid,n_jobs = -1,cv=3,verbose=0)\n\n# Fitting the estimator with training data\ngrid6.fit(X_train6,y_train6)\n\nprint(f\"Best Score: {grid6.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid6.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_ET6 = pd.DataFrame(grid6.cv_results_)\nres_ET6   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Score: 0.6620241411327762\n\nBest Estimator: ExtraTreesClassifier(max_depth=14, n_estimators=200, random_state=42)","metadata":{}},{"cell_type":"code","source":"res_ET6 .to_csv(\"res_ET6.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_ET6.loc[res_ET6['mean_test_score'] == max(res_ET6.loc[:,'mean_test_score']),:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"nbr_combision_paramètre=res_ET6.index\naccuracy=res_ET6['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison \n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### b) MLPClassifier","metadata":{}},{"cell_type":"code","source":"estimator = MLPClassifier(max_iter=100)\n\nparameters = {\n    'hidden_layer_sizes': [(10,30,10),(20,)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive','invscaling'],\n    'batch_size' : [10,30,60]\n}\n\ngrid6 = GridSearchCV(estimator = estimator, param_grid = parameters,n_jobs = -1,cv=3,verbose=0)\n\n# Fitting the estimator with training data\ngrid6.fit(X_train6,y_train6)\n\nprint(f\"Best Score: {grid6.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid6.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_MLP6 = pd.DataFrame(grid1.cv_results_)\nres_MLP6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Score: 0.6490250696378831\n\nBest Estimator: MLPClassifier(batch_size=10, hidden_layer_sizes=(20,), max_iter=100)\n\nGrid Search_ET1 CV results:","metadata":{}},{"cell_type":"code","source":"res_MLP6 .to_csv(\"res_ET6.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_MLP6.loc[res_MLP6['mean_test_score'] == max(res_MLP6.loc[:,'mean_test_score']),:]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"nbr_combision_paramètre=res_MLP6.index\naccuracy=res_MLP6['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison \n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### c) SVC","metadata":{}},{"cell_type":"code","source":"param_grid = {'C': [0.1, 1, 10, 100],\n              'gamma': [1, 0.1, 0.01],\n              'kernel': ['linear','poly','rbf'],\n              'random_state' : [0,10,42]}\n\ngrid3 = GridSearchCV(SVC(), param_grid, refit = True, cv = 3, n_jobs = -1, verbose = 0)\n\n# Fitting the estimator with training data\ngrid3.fit(X_train6,y_train6)\n\nprint(f\"Best Score: {grid3.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Model: {grid3.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_SVC6 = pd.DataFrame(grid3.cv_results_)\nres_SVC6","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Score: 0.6694521819870008\n\nBest Model: SVC(C=10, gamma=0.1, random_state=0)\n\nGrid Search_ET1 CV results:","metadata":{}},{"cell_type":"code","source":"res_SVC6 .to_csv(\"res_SVC6.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_SVC6.loc[res_SVC6['mean_test_score'] == max(res_SVC6.loc[:,'mean_test_score']),:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"nbr_combision_paramètre=res_SVC6.index\naccuracy=res_SVC6['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison \n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4- Sélection du meilleur modèle\nLe modèle ayant eu le meilleur score est SVC\n","metadata":{}},{"cell_type":"code","source":"model =SVC(C=10, gamma=0.1, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5) Application du modèle sur d'autres datasets","metadata":{}},{"cell_type":"markdown","source":"#### a) Train1slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train1,y_train1)\n\npredicted_test = model.predict(X_test1)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test1, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test1,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.6060606060606061","metadata":{}},{"cell_type":"markdown","source":"#### b) Train2slice","metadata":{}},{"cell_type":"markdown","source":"\n\n","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train2,y_train2)\n\npredicted_test = model.predict(X_test2)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test2, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test2,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7007575757575758","metadata":{}},{"cell_type":"markdown","source":"#### c) Train3slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train3,y_train3)\n\npredicted_test = model.predict(X_test3)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test3, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test3,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7348484848484849","metadata":{}},{"cell_type":"markdown","source":"#### d) Train4slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train4,y_train4)\n\npredicted_test = model.predict(X_test4)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test4, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test4,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7348484848484849","metadata":{}},{"cell_type":"markdown","source":"#### e) Train5slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train,y_train)\n\npredicted_test = model.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7592592592592593","metadata":{}},{"cell_type":"markdown","source":"#### f) Train6slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train6,y_train6)\n\npredicted_test = model.predict(X_test6)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test6, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test6,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7462121212121212","metadata":{}},{"cell_type":"markdown","source":"#### g) Train7slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train7,y_train7)\n\npredicted_test = model.predict(X_test7)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test7, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test7,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.75","metadata":{}},{"cell_type":"markdown","source":"#### h) Train8slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train8,y_train8)\n\npredicted_test = model.predict(X_test8)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test8, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test8,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7424242424242424","metadata":{}},{"cell_type":"markdown","source":"#### i) Train9slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train9,y_train9)\n\npredicted_test = model.predict(X_test9)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test9, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test9,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7424242424242424","metadata":{}},{"cell_type":"markdown","source":"#### j) Train10slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train10,y_train10)\n\npredicted_test = model.predict(X_test10)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test10, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test10,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score =0.7424242424242424\n\n\nA l'issue de nos analyses, on remarque que les résulats obtenus en appliquant le modèle sur d'autres Datasets est légèrement plus élevé que dans les cas précédents. Cela veut dire qu'avec 4 slices, nos modèles apprennent déjà un peu mieux.\n\nPassons maintenant au train4slices. On répète le même processus.  \n\n\n## Train7slices\n\n### 1- Tester plusieurs modèles","metadata":{}},{"cell_type":"code","source":"# Nous allons comparer les modèles entre eux en vue de sélectionner ceux qui auront le meilleur score\n\nmodels = [AdaBoostClassifier(),RandomForestClassifier(), BaggingClassifier(), GradientBoostingClassifier(),\n          ExtraTreesClassifier(),\n         LogisticRegression(max_iter=10000),Perceptron(),RidgeClassifier(),PassiveAggressiveClassifier(),\n         SVC(),LinearSVC(),NuSVC(),\n         KNeighborsClassifier(), MLPClassifier(),DecisionTreeClassifier(),LGBMClassifier()]\nnames = [\"AdaBoost\",\"RandomForest\", \"BaggingClassifier\",\"GradientBoostingClassifier\",\"ExtraTrees\",\n         \"LogisticRegression\", \"Perceptron\", \"RidgeClassifier\",\"PassiveAggressiveClassifier\",\n         \"SVC\",\"LinearSVC()\", \"NuSVC\",\n         \"KNeighborsClassifier\", \"MLPClassifier\",\"DecisionTreeClassifier\",\"LGBMClassifier\"]\naccuracy=[]\nrecall=[]\ni=0\nfor model in models:\n    model.fit(X_train7,y_train7)\n    predicted = model.predict(X_test7)\n    acc = accuracy_score(y_test7, predicted)\n    rec= recall_score(y_test7, predicted, average= 'weighted')\n    accuracy.append(acc)\n    recall.append(rec)\n#     print(\"Accuracy de \", names[i],\":\", accuracy[i])\n    i+=1\n\ndf7= pd.DataFrame({'models' : names, 'accuracy_score' : accuracy, 'recall_score' : recall})\ndf7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2- Modèles ayant donné l'accuracy_score le plus élevé","metadata":{}},{"cell_type":"code","source":"# Sélection des meilleurs modèles en fonction de l'accuracy_score \n\nbest_models7 = df7[ (df7['accuracy_score'] >= 0.68) ]\nbest_models7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Les modèles retenus à ce stade sont : ExtraTrees, MLPClassifier,SVC ","metadata":{}},{"cell_type":"markdown","source":"### 3- Optimisation des modèles grâce à un GridSearch","metadata":{}},{"cell_type":"markdown","source":"#### a) ExtraTrees","metadata":{}},{"cell_type":"code","source":" param_grid = {'n_estimators': np.arange(50,300,30),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(3,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\n\ngrid7 = GridSearchCV(ExtraTreesClassifier(), param_grid,n_jobs = -1,cv=3,verbose=0)\n\n# Fitting the estimator with training data\ngrid7.fit(X_train7,y_train7)\n\nprint(f\"Best Score: {grid7.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid7.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_ET7 = pd.DataFrame(grid7.cv_results_)\nres_ET7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Score: 0.6620241411327763\n\nBest Estimator: ExtraTreesClassifier(max_depth=14, n_estimators=200, random_state=0)\n\nGrid Search_ET1 CV results:","metadata":{}},{"cell_type":"code","source":"res_ET7.to_csv(\"res_ET7.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_ET7.loc[res_ET7['mean_test_score'] == max(res_ET7.loc[:,'mean_test_score']),:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"nbr_combision_paramètre=res_ET7.index\naccuracy=res_ET7['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison \n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" b)MLPClassifier","metadata":{}},{"cell_type":"code","source":"estimator = MLPClassifier(max_iter=100)\n\nparameters = {\n    'hidden_layer_sizes': [(10,30,10),(20,)],\n    'activation': ['tanh', 'relu'],\n    'solver': ['sgd', 'adam'],\n    'alpha': [0.0001, 0.05],\n    'learning_rate': ['constant','adaptive','invscaling'],\n    'batch_size' : [10,30,60]\n}\n\ngrid7 = GridSearchCV(estimator = estimator, param_grid = parameters,n_jobs = -1,cv=3,verbose=0)\n\n# Fitting the estimator with training data\ngrid7.fit(X_train7,y_train7)\n\nprint(f\"Best Score: {grid7.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid7.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_MLP7 = pd.DataFrame(grid7.cv_results_)\nres_MLP7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Score: 0.6434540389972144\n\nBest Estimator: MLPClassifier(batch_size=10, hidden_layer_sizes=(20,), max_iter=100)\n\nGrid Search_ET1 CV results:","metadata":{}},{"cell_type":"code","source":"res_MLP7.to_csv(\"res_MLP7.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_MLP7.loc[res_MLP7['mean_test_score'] == max(res_MLP7.loc[:,'mean_test_score']),:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"nbr_combision_paramètre=res_MLP7.index\naccuracy=res_MLP7['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison \n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"c)SVC","metadata":{}},{"cell_type":"code","source":"param_grid = {'C': [0.1, 1, 10, 100],\n              'gamma': [1, 0.1, 0.01],\n              'kernel': ['linear','poly','rbf'],\n              'random_state' : [0,10,42]}\n\ngrid3 = GridSearchCV(SVC(), param_grid, refit = True, cv = 3, n_jobs = -1, verbose = 0)\n\n# Fitting the estimator with training data\ngrid3.fit(X_train7,y_train7)\n\nprint(f\"Best Score: {grid3.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Model: {grid3.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\nres_SVC7 = pd.DataFrame(grid3.cv_results_)\nres_SVC7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Score: 0.6685236768802229\n\nBest Model: SVC(C=10, gamma=0.1, random_state=0)\n\nGrid Search_ET1 CV results:","metadata":{}},{"cell_type":"code","source":"res_SVC7.to_csv(\"res_MLP7.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Historique combinaison des paramètres et le temps d'apprentissage pour le meilleur modèle\nres_SVC7.loc[res_SVC7['mean_test_score'] == max(res_SVC7.loc[:,'mean_test_score']),:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Graphe de l'évolution de l'accuracy_score pour chaque fold","metadata":{}},{"cell_type":"code","source":"nbr_combision_paramètre=res_SVC7.index\naccuracy=res_SVC7['mean_test_score']\n#evolution de l'accuracy en fonction de differentes combinaison \n\nplt.plot(nbr_combision_paramètre,accuracy,color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.title(\"variation de l'accuracy en foncion des combisons des paramètre\")\nplt.xlabel(\"combinaison\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4- Sélection du meilleur modèle\nLe modèle ayant eu le meilleur score est svm\n","metadata":{}},{"cell_type":"code","source":"model =SVC(C=10, gamma=0.1, random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5) Application du modèle sur d'autres datasets","metadata":{}},{"cell_type":"markdown","source":"#### a) Train1slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train1,y_train1)\n\npredicted_test = model.predict(X_test1)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test1, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test1,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.6060606060606061","metadata":{}},{"cell_type":"markdown","source":"#### b) Train2slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train2,y_train2)\n\npredicted_test = model.predict(X_test2)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test2, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test2,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.7007575757575758","metadata":{}},{"cell_type":"markdown","source":"#### c) Train3slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train3,y_train3)\n\npredicted_test = model.predict(X_test3)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test3, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test3,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.7348484848484849","metadata":{}},{"cell_type":"markdown","source":"#### d) Train4slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train4,y_train4)\n\npredicted_test = model.predict(X_test4)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test4, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test4,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.7348484848484849","metadata":{}},{"cell_type":"markdown","source":"#### e) Train5slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train,y_train)\n\npredicted_test = model.predict(X_test)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.7592592592592593","metadata":{}},{"cell_type":"code","source":"model.fit(X_train5,y_train5)\nprediction = model.predict(test5)\noutput = pd.DataFrame({'label':prediction })\noutput['id'] = range(0,len(output))\n\ncolumnsTitles=[\"id\",\"label\"]\noutput = output.reindex(columns=columnsTitles)\n\noutput.to_csv(\"submission_SVC_ovo.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### f) Train6slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train6,y_train6)\n\npredicted_test = model.predict(X_test6)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test6, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test6,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.7462121212121212","metadata":{}},{"cell_type":"markdown","source":"#### g) Train7slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train7,y_train7)\n\npredicted_test = model.predict(X_test7)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test7, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test7,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.75","metadata":{}},{"cell_type":"markdown","source":"#### h) Train8slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train8,y_train8)\n\npredicted_test = model.predict(X_test8)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test8, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test8,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.7424242424242424","metadata":{}},{"cell_type":"markdown","source":"#### i) Train9slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train9,y_train9)\n\npredicted_test = model.predict(X_test9)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test8, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test8,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.7424242424242424","metadata":{}},{"cell_type":"markdown","source":"#### j) Train10slice","metadata":{}},{"cell_type":"code","source":"# fit the model\nmodel.fit(X_train10,y_train10)\n\npredicted_test = model.predict(X_test10)\n\n#Confusion matrix for the train_prediction\nimport seaborn as sns\ncm = confusion_matrix(y_test10, predicted_test)\nax= plt.subplot()\nsns.heatmap(cm, annot=True, fmt='g', ax=ax)\n\n# # labels and title \n\nplt.title('Confusion Matrix',fontsize = 15)\nplt.xlabel('Predicted label')\nplt.ylabel('True label')\nplt.show() \n\n# #print the confusion matrix\n# print(f\"Confusion matrix:\\n{cm}\")  \n\n# print the accuracy  \nacc_t =accuracy_score(y_test10,predicted_test)\nprint(acc_t)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy_score=0.7424242424242424","metadata":{}},{"cell_type":"markdown","source":"##### Graphe montrant l'effet et l'évolution de l'accuracy si on utilise une données d'apprentissage pour construire un model avec un nombre de slice élevé","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nmodel_slice1_acc=[0.6591,0.7235,0.7386,0.7311,0.74814,0.7083,0.7159,0.7348,0.7272,0.7614]\nmodel_slice2_acc=[0.6477,0.7335,0.7121,0.6893,0.73,0.6591,0.6591,0.64391,0.6439,0.6477]\nmodel_slice3_acc= [0.6515,0.6705,0.71,0.7008,0.73333,0.6969,0.6969,0.7272,0.6893,0.6666]\nmodel_slice4_acc=[0.6932,0.7008,0.7348,0.7442,0.7074,0.7386,0.7272,0.7196,0.7577,0.75]\nmodel_slice6_acc=[0.6060,0.7070,0.7345,0.73348,0.7593,0.7462,0.75,0.7424,0.7424,0.7424]\nmodel_slice7_acc=[0.6060,0.7007,0.7348,0.7348,0.7593,0.7462,0.75,0.7427,0.7424,0.7442]\n\n\npd=pd.DataFrame({'acc_test1':model_slice1_acc,'acc_test2':model_slice2_acc,'acc_test3':model_slice3_acc,'acc_test4':model_slice4_acc,'acc_test6':model_slice6_acc,'acc_test7':model_slice7_acc})","metadata":{"execution":{"iopub.status.busy":"2021-12-01T14:06:17.89728Z","iopub.execute_input":"2021-12-01T14:06:17.897974Z","iopub.status.idle":"2021-12-01T14:06:17.906453Z","shell.execute_reply.started":"2021-12-01T14:06:17.897935Z","shell.execute_reply":"2021-12-01T14:06:17.905342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd","metadata":{"execution":{"iopub.status.busy":"2021-12-01T14:06:20.444395Z","iopub.execute_input":"2021-12-01T14:06:20.444737Z","iopub.status.idle":"2021-12-01T14:06:20.45911Z","shell.execute_reply.started":"2021-12-01T14:06:20.444703Z","shell.execute_reply":"2021-12-01T14:06:20.458293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.plot(range(10),pd['acc_test1'],color=\"blue\",linestyle=\"--\", marker = \"o\",linewidth=2)\nplt.plot(range(10),pd['acc_test2'],color=\"red\",linestyle=\"-.\", marker = \"D\",linewidth=2)\nplt.plot(range(10),pd['acc_test3'],color=\"yellow\",linestyle=\"-.\", marker = \"D\",linewidth=2)\nplt.plot(range(10),pd['acc_test4'],color=\"violet\",linestyle=\"-.\", marker = \"D\",linewidth=2)\nplt.plot(range(10),pd['acc_test6'],color=\"gold\",linestyle=\"-.\", marker = \"D\",linewidth=2)\nplt.plot(range(10),pd['acc_test7'],color=\"m\",linestyle=\"-.\", marker = \"D\",linewidth=2)\nplt.title(\"evolution des accuracy du Models construit avec train i sur test i\")\nplt.xlabel(\"Models construit avec train i\")\nplt.ylabel(\"accuracy sur test i\")\nplt.legend([\"test1\", \"test2\",\"test3\",\"test4\",\"test6\",\"test7\"], loc =\"lower right\")\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-01T14:15:54.152003Z","iopub.execute_input":"2021-12-01T14:15:54.152512Z","iopub.status.idle":"2021-12-01T14:15:54.439423Z","shell.execute_reply.started":"2021-12-01T14:15:54.152476Z","shell.execute_reply":"2021-12-01T14:15:54.438423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"cette courbe explique l'influence du nombre de slices pour la prédiction.\nLa courbe évolue par ce que si nous utilisons pluisieurs slices ,le model apprend bien et est capable de tout interpreter si on lui donne comme ensemble de test un slice plus petit \nNéamoins si on essaie de prendre le model construit sur le train set  de 10 slices pour prédire le test set de 1 slice un phénomène de surapprentissage se produit. \n\nOn estime que le model a n'a plus les informations nécessaires à cause de l'écart conséquent entre les slices.","metadata":{}},{"cell_type":"markdown","source":"# Partie3 : Graphes de l'évolution de l'accuracy finale en fonction du nombre de slices\n\nDans cette partie, nous allons voir l’influence du nombre de slices sur l’Accuracy finale. Remarquons d’abord que pour les ensembles d’apprentissages utilisés, les classifieurs qui reviennent souvent sont les suivants :  RandomForest ,MLPClassifier. Nous avons donc optimisé ces modèles grâce à un gridSearch et nous obtenons pour chaque classifieur, les graphes suivants qui traduisent l’évolution de l’accuracy en fonction du nombre de slices ","metadata":{}},{"cell_type":"markdown","source":"## RandomForest","metadata":{}},{"cell_type":"code","source":"final_acc_RF = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train1slice\n param_grid = {'n_estimators': np.arange(50,300,50),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(5,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\ngrid1 = GridSearchCV(RandomForestClassifier(), param_grid,n_jobs = -1,cv=3,verbose=1)\n# Fitting the estimator with training data\ngrid1.fit(X_train1,y_train1)\nprint(f\"Best Estimator: {grid1.best_estimator_}\", end=\"\\n\\n\")\nprint(f\"Best Score: {grid1.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF1 = pd.DataFrame(grid1.cv_results_)\nmodel1 = grid1.best_estimator_\n#Prediction\npredicted_test = model1.predict(X_test1)\n\nacc1 = accuracy_score(y_test1,predicted_test)\n\nfinal_acc_RF.append(acc1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train2slices\n \nparam_grid = {'n_estimators': np.arange(50,300,50),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(5,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\ngrid2 = GridSearchCV(RandomForestClassifier(), param_grid,n_jobs = -1,cv=3,verbose=1)\n# Fitting the estimator with training data\ngrid2.fit(X_train2,y_train2)\nprint(f\"Best Estimator: {grid2.best_estimator_}\", end=\"\\n\\n\")\nprint(f\"Best Score: {grid2.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF2 = pd.DataFrame(grid2.cv_results_)\n#res_RF2    # Résultats du gridsearch pour le classifieur Random Forest du train2slices \nmodel2 = grid2.best_estimator_\n#Prediction\npredicted_test = model2.predict(X_test2)\n\nacc2 = accuracy_score(y_test2,predicted_test)\n\nfinal_acc_RF.append(acc2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train3slices\n \nparam_grid = {'n_estimators': np.arange(50,300,50),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(5,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\ngrid3 = GridSearchCV(RandomForestClassifier(), param_grid,n_jobs = -1,cv=3,verbose=1)\n# Fitting the estimator with training data\ngrid3.fit(X_train3,y_train3)\nprint(f\"Best Estimator: {grid3.best_estimator_}\", end=\"\\n\\n\")\nprint(f\"Best Score: {grid3.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF3 = pd.DataFrame(grid3.cv_results_)\n# res_RF3    # Résultats du gridsearch pour le classifieur Random Forest du train3slices \nmodel3 = grid3.best_estimator_\n#Prediction\npredicted_test = model3.predict(X_test3)\n\nacc3 = accuracy_score(y_test3,predicted_test)\n\nfinal_acc_RF.append(acc3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train4slices\n \nparam_grid = {'n_estimators': np.arange(50,300,50),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(5,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\ngrid4 = GridSearchCV(RandomForestClassifier(), param_grid,n_jobs = -1,cv=3,verbose=1)\n# Fitting the estimator with training data\ngrid4.fit(X_train4,y_train4)\nprint(f\"Best Estimator: {grid4.best_estimator_}\", end=\"\\n\\n\")\nprint(f\"Best Score: {grid4.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF4 = pd.DataFrame(grid4.cv_results_)\n# res_RF4    # Résultats du gridsearch pour le classifieur Random Forest du train4slices \nmodel4 = grid4.best_estimator_\n#Prediction\npredicted_test = model4.predict(X_test4)\n\nacc4 = accuracy_score(y_test4,predicted_test)\n\nfinal_acc_RF.append(acc4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train6slices\n \nparam_grid = {'n_estimators': np.arange(50,300,50),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(5,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\ngrid6 = GridSearchCV(RandomForestClassifier(), param_grid,n_jobs = -1,cv=3,verbose=1)\n# Fitting the estimator with training data\ngrid6.fit(X_train6,y_train6)\nprint(f\"Best Estimator: {grid6.best_estimator_}\", end=\"\\n\\n\")\nprint(f\"Best Score: {grid6.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF6 = pd.DataFrame(grid6.cv_results_)\n# res_RF6    # Résultats du gridsearch pour le classifieur Random Forest du train6slices \nmodel6 = grid6.best_estimator_\n#Prediction\npredicted_test = model6.predict(X_test6)\n\nacc6 = accuracy_score(y_test6,predicted_test)\n\nfinal_acc_RF.append(acc6)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train10slices\n \nparam_grid = {'n_estimators': np.arange(50,300,50),\n              'criterion':('gini','entropy'),\n              'max_depth' : np.arange(5,21),\n             'max_features':('auto','sqrt'),\n              'random_state': [0,10,42]}\ngrid10 = GridSearchCV(RandomForestClassifier(), param_grid,n_jobs = -1,cv=3,verbose=1)\n# Fitting the estimator with training data\ngrid10.fit(X_train10,y_train10)\nprint(f\"Best Estimator: {grid10.best_estimator_}\", end=\"\\n\\n\")\nprint(f\"Best Score: {grid10.best_score_}\", end=\"\\n\\n\")\nprint(\"Grid Search_RF1 CV results:\")\nres_RF10 = pd.DataFrame(grid10.cv_results_)\n# res_RF10    # Résultats du gridsearch pour le classifieur Random Forest du train10slices \nmodel10 = grid10.best_estimator_\n#Prediction\npredicted_test = model10.predict(X_test10)\n\nacc10 = accuracy_score(y_test10,predicted_test)\n\nfinal_acc_RF.append(acc10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Graphe de l'écolution de l'accuracy finale en fonction du nombre de slices","metadata":{}},{"cell_type":"code","source":"\nx = [1,2,3,4,6,10]\ny = final_acc_RF \n\nplt.plot(x,y,color=\"blue\",linestyle=\"-\", marker = \"o\",linewidth=2)\nplt.title(\"Evolution de l'accuracy finale en foncion du nombre de slices\")\nplt.xlabel(\"nombre de slices\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-On obtient les meilleurs scores pour 4 slices et pour 10 slices.  \n-L'accuracy obtenune avec 6 slices est la plus faible.  \n-On peut donc dire que l'accuracy finale n'augmente pas systématiquement avec plus de slices.","metadata":{}},{"cell_type":"markdown","source":"### MLPClassifier","metadata":{}},{"cell_type":"code","source":"final_acc_MLP = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tain1slices\n# First, we are defining parameter range\n\nparam_grid = {'hidden_layer_sizes': range(10,90,10),\n              'solver': ['sgd','adam'],\n              'learning_rate_init': [0.001,0.01],\n              'momentum' : [0.5,0.9,1]}\n\ngrid1 = GridSearchCV(estimator= MLPClassifier(max_iter = 10000),param_grid = param_grid, cv = 3, n_jobs = -1,verbose = 1)\n\n# fitting the model for grid search. First\ngrid1.fit(X_train1, y_train1)\n\n\nprint(f\"Best Score: {grid1.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid1.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\n\nres_MLP1 = pd.DataFrame(grid1.cv_results_)\n# res_MLP1\n\nmodel1 = grid1.best_estimator_\n#Prediction\npredicted_test = model1.predict(X_test1)\n\nacc1 = accuracy_score(y_test1,predicted_test)\n\nfinal_acc_MLP.append(acc1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tain2slices\n# First, we are defining parameter range\n\nparam_grid = {'hidden_layer_sizes': range(10,90,10),\n              'solver': ['sgd','adam'],\n              'learning_rate_init': [0.001,0.01],\n              'momentum' : [0.5,0.9,1]}\n\ngrid2 = GridSearchCV(estimator= MLPClassifier(max_iter = 10000),param_grid = param_grid, cv = 3, n_jobs = -1,verbose = 1)\n\n# fitting the model for grid search. First\ngrid2.fit(X_train2, y_train2)\n\n\nprint(f\"Best Score: {grid2.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid2.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\n\nres_MLP2 = pd.DataFrame(grid2.cv_results_)\n# res_MLP2\n\nmodel2 = grid2.best_estimator_\n#Prediction\npredicted_test = model2.predict(X_test2)\n\nacc2 = accuracy_score(y_test2,predicted_test)\n\nfinal_acc_MLP.append(acc2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tain3slices\n# First, we are defining parameter range\n\nparam_grid = {'hidden_layer_sizes': range(10,90,10),\n              'solver': ['sgd','adam'],\n              'learning_rate_init': [0.001,0.01],\n              'momentum' : [0.5,0.9,1]}\n\ngrid3 = GridSearchCV(estimator= MLPClassifier(max_iter = 10000),param_grid = param_grid, cv = 3, n_jobs = -1,verbose = 1)\n\n# fitting the model for grid search. First\ngrid3.fit(X_train3, y_train3)\n\n\nprint(f\"Best Score: {grid3.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid3.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\n\nres_MLP3 = pd.DataFrame(grid3.cv_results_)\n# res_MLP3\n\nmodel3 = grid3.best_estimator_\n#Prediction\npredicted_test = model3.predict(X_test3)\n\nacc3 = accuracy_score(y_test3,predicted_test)\n\nfinal_acc_MLP.append(acc3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tain4slices\n# First, we are defining parameter range\n\nparam_grid = {'hidden_layer_sizes': range(10,90,10),\n              'solver': ['sgd','adam'],\n              'learning_rate_init': [0.001,0.01],\n              'momentum' : [0.5,0.9,1]}\n\ngrid4 = GridSearchCV(estimator= MLPClassifier(max_iter = 10000),param_grid = param_grid, cv = 3, n_jobs = -1,verbose = 1)\n\n# fitting the model for grid search. First\ngrid4.fit(X_train4, y_train4)\n\n\nprint(f\"Best Score: {grid4.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid4.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\n\nres_MLP4 = pd.DataFrame(grid4.cv_results_)\nres_MLP4\n\nmodel4 = grid4.best_estimator_\n#Prediction\npredicted_test = model4.predict(X_test4)\n\nacc4 = accuracy_score(y_test4,predicted_test)\n\nfinal_acc_MLP.append(acc4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tain6slices\n# First, we are defining parameter range\n\nparam_grid = {'hidden_layer_sizes': range(10,90,10),\n              'solver': ['sgd','adam'],\n              'learning_rate_init': [0.001,0.01],\n              'momentum' : [0.5,0.9,1]}\n\ngrid6 = GridSearchCV(estimator= MLPClassifier(max_iter = 10000),param_grid = param_grid, cv = 3, n_jobs = -1,verbose = 1)\n\n# fitting the model for grid search. First\ngrid6.fit(X_train6, y_train6)\n\n\nprint(f\"Best Score: {grid6.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid6.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\n\nres_MLP6 = pd.DataFrame(grid6.cv_results_)\n# res_MLP6\n\nmodel6 = grid6.best_estimator_\n#Prediction\npredicted_test = model6.predict(X_test6)\n\nacc6 = accuracy_score(y_test6,predicted_test)\n\nfinal_acc_MLP.append(acc6)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tain10slices\n# First, we are defining parameter range\n\nparam_grid = {'hidden_layer_sizes': range(10,90,10),\n              'solver': ['sgd','adam'],\n              'learning_rate_init': [0.001,0.01],\n              'momentum' : [0.5,0.9,1]}\n\ngrid10 = GridSearchCV(estimator= MLPClassifier(max_iter = 10000),param_grid = param_grid, cv = 3, n_jobs = -1,verbose = 1)\n\n# fitting the model for grid search. First\ngrid10.fit(X_train10, y_train10)\n\n\nprint(f\"Best Score: {grid4.best_score_}\", end=\"\\n\\n\")\nprint(f\"Best Estimator: {grid4.best_estimator_}\", end=\"\\n\\n\")\nprint(\"Grid Search_ET1 CV results:\")\n\nres_MLP10 = pd.DataFrame(grid10.cv_results_)\n# res_MLP10\n\nmodel10 = grid10.best_estimator_\n#Prediction\npredicted_test = model10.predict(X_test10)\n\nacc10 = accuracy_score(y_test10,predicted_test)\n\nfinal_acc_MLP.append(acc10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Graphe de l'évolution de l'accuracy finale en fonction du nombre de slices","metadata":{}},{"cell_type":"code","source":"x = [1,2,3,4,6,10]\ny = final_acc_MLP\n\nplt.title(\"Evolution de l'accuracy finale en foncion du nombre de slices\")\nplt.xlabel(\"nombre de slices\")\nplt.ylabel(\"accuracy\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Comme dans le cas précédent, on conclut que l'accuracy n'augmente pas systématiquement lorsque le nombre de slices augmente.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}